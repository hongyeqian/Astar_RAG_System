====================================================================================================
HIERARCHICAL CHUNKING RESULTS - CONVERSATION LEVEL
Generated: 2025-11-06 23:03:35
Total Chunks: 185
====================================================================================================

>>> MEETING: data001 <<<
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[CHUNK #1]
Chunk ID: data001_conv_0
Meeting ID: data001
Level: conversation
Text Length: 360 characters

Text Content:
----------------------------------------------------------------------------------------------------
# Data001
00](http://www.youtube.com/watch?v=xqXa-i-Fr-M&t=0)] **Satya Nadella:** Thank you so much, Elon, for being here at Build. I know you started off as an intern at Microsoft. You were a Windows developer, and of course you're a big PC gamer still. You want to just talk about you and your early days with Windows and the kinds of things you built? Yeah.
----------------------------------------------------------------------------------------------------


[CHUNK #2]
Chunk ID: data001_conv_1
Meeting ID: data001
Level: conversation
Text Length: 354 characters

Text Content:
----------------------------------------------------------------------------------------------------
27](http://www.youtube.com/watch?v=xqXa-i-Fr-M&t=27)] **Elon Musk:** Well, actually it started before Windows with DOS. I had one of the early IBM PCs with MS-DOS, and I think it had like 128k in the beginning, and then it doubled to 256k, which felt like a lot. So, yeah, I programmed video games in DOS, and then later in Windows. Remember Windows 3.1?
----------------------------------------------------------------------------------------------------


[CHUNK #3]
Chunk ID: data001_conv_2
Meeting ID: data001
Level: conversation
Text Length: 733 characters

Text Content:
----------------------------------------------------------------------------------------------------
43](http://www.youtube.com/watch?v=xqXa-i-Fr-M&t=43)] **Satya Nadella:** Yeah. No, it's wonderful. Even the last time I chatted with you, you were talking all about everything, the intricacies of Active Directory. And so, it's fantastic to have you at our developer conference. Obviously, the exciting thing for us is to be able to launch Grok on Azure. I know you have a deep vision for what AI needs to be, and that's what got you to get this built. It's a family of models that are both response and reasoning models, and you have a very exciting roadmap. You want to just tell us a little bit about your vision, the capability? You're pushing on both capability and efficiency. Maybe you can just talk about a little bit of that.
----------------------------------------------------------------------------------------------------


[CHUNK #4]
Chunk ID: data001_conv_3
Meeting ID: data001
Level: conversation
Text Length: 1676 characters

Text Content:
----------------------------------------------------------------------------------------------------
17](http://www.youtube.com/watch?v=xqXa-i-Fr-M&t=77)] **Elon Musk:** Sure. So yeah, with Grok, especially with Grok 3.5 that is about to be released, it's trying to reason from first principles, so apply kind of the the tools of physics to thinking. So, if you're trying to get to fundamental truths you boil things down to the axiomatic elements that are most likely to be correct, and then you reason up from there. And then you can test your conclusions against those axiomatic elements. And in physics, if you violate conservation of energy or momentum, then you're either get going to get a Nobel Prize or you're wrong, and you're almost certainly wrong, basically. So, that's really, the focus of Grok 3.5 is sort of, find the fundamentals of physics and applying physics tools across all lines of reasoning, and to aspire to truth with minimal error. Like, there's always going to be some mistakes that are made, but aim to get to truth with acknowledged error, but minimize that error over time. I think that's actually extremely important for AI safety. I've thought a lot for a long time about AI safety, and my ultimate conclusion is the old maxim that "honesty is the best policy." It really, really is for safety. But I do want to emphasize, we have and will make mistakes, but we aspire to correct them very quickly, and we are very much looking forward to feedback from the developer community to say, like, what do you need, where are we wrong, how can we make it better? And to have Grok be something that the developer community is very excited to use, and where they can feel that their feedback is being heard and Grok is improving and serving their needs.
----------------------------------------------------------------------------------------------------


[CHUNK #5]
Chunk ID: data001_conv_4
Meeting ID: data001
Level: conversation
Text Length: 1001 characters

Text Content:
----------------------------------------------------------------------------------------------------
10](http://www.youtube.com/watch?v=xqXa-i-Fr-M&t=190)] **Satya Nadella:** Yeah, no, it's, in some sense, cracking the physics of intelligence is perhaps the real goal for us to be able to use AI at scale. And so, it's so good to take that first principles approach that you and your team are taking. And also you're deploying this. I mean, one of the things about what you do is you're doing unsupervised FSD on one side, you're doing robotics. Of course there's Grok, so you're deploying Grok across all of your businesses, from SpaceX to Tesla, obviously at X. I would love to even, one of the themes for this developer conference, Elon, is we're building pretty sophisticated AI apps, right? It's not even about any one model. It's about orchestrating multiple models, multiple agents. Just anything that you're seeing in the real world application side, even inside of your own companies, when you think about even a Tesla or a SpaceX, where you put Grok and these other AI models you're building?
----------------------------------------------------------------------------------------------------


[CHUNK #6]
Chunk ID: data001_conv_5
Meeting ID: data001
Level: conversation
Text Length: 1559 characters

Text Content:
----------------------------------------------------------------------------------------------------
18](http://www.youtube.com/watch?v=xqXa-i-Fr-M&t=258)] **Elon Musk:** Yeah, it's incredibly important for an AI model to be grounded in reality. Reality, I was saying, which is like physics is the law and everything else is a recommendation. Which I'm not suggesting people break the laws made by humans. We should generally obey laws of humans, but I've seen many people break human-made laws, but I have not seen anyone break the laws of physics. For any given AI, grounding it against reality, and reality, for example, as you mentioned with the car, it needs to drive safely and correctly. The humanoid robot Optimus needs to perform the task that it's being asked to perform. These are things that are very helpful for ensuring that the model is truthful and accurate, because it has to adhere to the laws of physics. So, I think that's actually maybe somewhat overlooked, or at least not talked about enough, is that to really be intelligent, it's got to make predictions that are in line with reality, in other words, physics. It's a really fundamental thing. Being able to ground that with cars and robots is very important. We are seeing Grok be very helpful in things like customer service, and the AI is infinitely patient and friendly, and you can yell at it, and it's still going to be very nice. That's good. Yeah. And so, I think that terms of improving the quality of customer service and issue resolution, AI is already, Grok is already doing quite a good job that at SpaceX and Tesla, and we look forward to offering that to other companies.
----------------------------------------------------------------------------------------------------


[CHUNK #7]
Chunk ID: data001_conv_6
Meeting ID: data001
Level: conversation
Text Length: 614 characters

Text Content:
----------------------------------------------------------------------------------------------------
00](http://www.youtube.com/watch?v=xqXa-i-Fr-M&t=360)] **Satya Nadella:** No, that's fantastic. Really thrilled to get this journey started, getting that developer feedback, and then looking forward to even how they deploy. There are these language models. I think over time, we will have this coming together of language models with vision, with action, but to your point, being really grounded on a real world model, and that, I think, is ultimately the goal here. Thank you so much, Elon, for briefly joining us today, and we're really excited about working with you and getting this into the developers' hands.
----------------------------------------------------------------------------------------------------


[CHUNK #8]
Chunk ID: data001_conv_7
Meeting ID: data001
Level: conversation
Text Length: 241 characters

Text Content:
----------------------------------------------------------------------------------------------------
28](http://www.youtube.com/watch?v=xqXa-i-Fr-M&t=388)] **Elon Musk:** Thank you very much. I can't emphasize enough that we're looking for feedback from you, the developer audience. Tell us what you want, and we'll make it happen. Thank you.
----------------------------------------------------------------------------------------------------



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

>>> MEETING: data004 <<<
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[CHUNK #9]
Chunk ID: data004_conv_0
Meeting ID: data004
Level: conversation
Text Length: 694 characters

Text Content:
----------------------------------------------------------------------------------------------------
# data004
00](http://www.youtube.com/watch?v=rKpltaOMFdc&t=0)] **Host:** All right, Balances, today's guest is someone I'm really excited to have on the show because, you know, when you just come across those profiles on Instagram and you're just magnetically drawn to someone... I feel like we almost have similar neural pathways in our brain, we think about things in a very similar way. So I think this is going to be a very synergistic, easy conversation. Our guest is the CEO of Speaker by **Nimi Mehta**. She's a TV and radio presenter, an MC, a podcast host, a speaker, a public speaking mentor. What don't you do? It's the beautiful Nimi Mehta on the podcast today, welcome to the show.
----------------------------------------------------------------------------------------------------


[CHUNK #10]
Chunk ID: data004_conv_1
Meeting ID: data004
Level: conversation
Text Length: 158 characters

Text Content:
----------------------------------------------------------------------------------------------------
41](http://www.youtube.com/watch?v=rKpltaOMFdc&t=41)] **Nimi Mehta:** Thank you so much for having me. I'm so excited to be here and to to synergize with you.
----------------------------------------------------------------------------------------------------


[CHUNK #11]
Chunk ID: data004_conv_2
Meeting ID: data004
Level: conversation
Text Length: 493 characters

Text Content:
----------------------------------------------------------------------------------------------------
44](http://www.youtube.com/watch?v=rKpltaOMFdc&t=44)] **Host:** Oh, I love it. There's going to be a lot of synergizing, I think. One of the first things that I was really interested in was your journey from completing your degree in journalism and getting your first job, which you have described as being your dream job at the time, and just that first year experience and what happened directly after, because I think that's important context to understand kind of where you've come to now.
----------------------------------------------------------------------------------------------------


[CHUNK #12]
Chunk ID: data004_conv_3
Meeting ID: data004
Level: conversation
Text Length: 879 characters

Text Content:
----------------------------------------------------------------------------------------------------
17](http://www.youtube.com/watch?v=rKpltaOMFdc&t=77)] **Nimi Mehta:** Yeah, that's a great first question. I did journalism at University, came straight out at the age of 21, and got the job to be an **MTV presenter**. And that for me just felt so normal at the time. When something like that happens to you, you think that life is that easy, especially at such a young age. I got the gig through an online competition where I submitted a video reel. I really produced, directed, and presented in that. But it was just what followed after. I really thought at that age that you have one goal post, you get to that goalpost, and then it's over. Obviously it wasn't. And it was a real hit to the ego. I realized that my dreams are ever evolving and ever changing, and sometimes when you think something is your dream, it's not—it's just a stepping stone towards the bigger picture.
----------------------------------------------------------------------------------------------------


[CHUNK #13]
Chunk ID: data004_conv_4
Meeting ID: data004
Level: conversation
Text Length: 186 characters

Text Content:
----------------------------------------------------------------------------------------------------
08](http://www.youtube.com/watch?v=rKpltaOMFdc&t=188)] **Host:** I think we've forgotten one key detail though. So you got the job at MTV, and then what happened that shattered your ego?
----------------------------------------------------------------------------------------------------


[CHUNK #14]
Chunk ID: data004_conv_5
Meeting ID: data004
Level: conversation
Text Length: 221 characters

Text Content:
----------------------------------------------------------------------------------------------------
18](http://www.youtube.com/watch?v=rKpltaOMFdc&t=198)] **Nimi Mehta:** Well, I was there for a year, and then the contract ended, and I was unemployed for a few years after that trying to hustle back in to be a presenter.
----------------------------------------------------------------------------------------------------


[CHUNK #15]
Chunk ID: data004_conv_6
Meeting ID: data004
Level: conversation
Text Length: 94 characters

Text Content:
----------------------------------------------------------------------------------------------------
28](http://www.youtube.com/watch?v=rKpltaOMFdc&t=208)] **Host:** So they just didn't renew it?
----------------------------------------------------------------------------------------------------


[CHUNK #16]
Chunk ID: data004_conv_7
Meeting ID: data004
Level: conversation
Text Length: 219 characters

Text Content:
----------------------------------------------------------------------------------------------------
29](http://www.youtube.com/watch?v=rKpltaOMFdc&t=209)] **Nimi Mehta:** Yeah, they didn't renew it. The channel concept they created, like District MTV, just wasn't picking up, so they ended it all. And that was me done.
----------------------------------------------------------------------------------------------------


[CHUNK #17]
Chunk ID: data004_conv_8
Meeting ID: data004
Level: conversation
Text Length: 631 characters

Text Content:
----------------------------------------------------------------------------------------------------
43](http://www.youtube.com/watch?v=rKpltaOMFdc&t=223)] **Host:** What a beautiful lesson to learn at such a young age that your dreams are ever evolving and that goals are just **markers along your journey**. It helps you enjoy the process. When you really zoom out all the way, you realize that's actually what life is. I had a similar experience where I thought that achieving a goal was going to feel a certain way, and it felt great, but then it was over, and it was like, "Okay, now what's the next part of life?" It's good to have had that reframe where you're like, "Okay, my goals are actually just markers of what's next."
----------------------------------------------------------------------------------------------------


[CHUNK #18]
Chunk ID: data004_conv_9
Meeting ID: data004
Level: conversation
Text Length: 366 characters

Text Content:
----------------------------------------------------------------------------------------------------
53](http://www.youtube.com/watch?v=rKpltaOMFdc&t=293)] **Nimi Mehta:** No one teaches us this. Life does, and these experiences teach you. I just think we need to know that **we are never ever the finished product**. That's what I was always chasing as a young individual. I thought, "Oh, overnight they were successes," but I think it built my character a lot more.
----------------------------------------------------------------------------------------------------


[CHUNK #19]
Chunk ID: data004_conv_10
Meeting ID: data004
Level: conversation
Text Length: 261 characters

Text Content:
----------------------------------------------------------------------------------------------------
39](http://www.youtube.com/watch?v=rKpltaOMFdc&t=339)] **Host:** So you were saying you were unemployed for a few years, and then what was the next thing, and how did you work out how to get to that place after being a little disappointed in that initial dream?
----------------------------------------------------------------------------------------------------


[CHUNK #20]
Chunk ID: data004_conv_11
Meeting ID: data004
Level: conversation
Text Length: 1651 characters

Text Content:
----------------------------------------------------------------------------------------------------
49](http://www.youtube.com/watch?v=rKpltaOMFdc&t=349)] **Nimi Mehta:** I really believe in the **power of proximity**. I thought, even though I was let go at MTV, they are under Viacom, and within Viacom they have brands like Nickelodeon. I thought, "I'm going to try and get a job at any of these companies, as long as I'm in the building." I thought someone would remember me or I would hear whispers of a new job. So I applied for an advert scheduler job at Nickelodeon. It was so monotonous, and nothing came of it. But I never lost sight, I never gave up hope. I also went through a **process of elimination**. I realized I should learn every single role possible within the media industry, 'cuz I might love being a producer or a director more than a presenter. I tried everything: editorial at my local newspaper, to *Hello* magazine, to an internship with ITV. I was so persistent with every work experience job. Back then, it was literally **showing up at the door with physical paper CVs**. I got one of my internships because a producer was not responding to my emails, and I just kept going—once a month for six to eight months. He finally said, "You are so persistent. Something's just come up." So, if you set your eyes on something, just keep going. Then I realized TV presenting is what I want to do, so I went into radio, as there was a lack of opportunity in TV in the UK. I went to a local radio station and did that for five months. I was shockingly bad. But five months later, I moved to **Radio 1 Abu Dhabi to host a national breakfast show**. That was a crazy journey for me, going from like a thousand people to a whole nation.
----------------------------------------------------------------------------------------------------


[CHUNK #21]
Chunk ID: data004_conv_12
Meeting ID: data004
Level: conversation
Text Length: 538 characters

Text Content:
----------------------------------------------------------------------------------------------------
25](http://www.youtube.com/watch?v=rKpltaOMFdc&t=565)] **Host:** Wow. You never know, every little thing has its role and leads you to exactly where you're meant to be. I'll share one thing that really helped me continue to be persistent: imagine you knew you had **50 "Nos" before you got a "Yes."** You'd be going as fast as you could to churn through all those. Seeing every rejection or setback as just, "That's one less one before my opportunity," has been a really great reframe for me to just keep going and not take it personally.
----------------------------------------------------------------------------------------------------


[CHUNK #22]
Chunk ID: data004_conv_13
Meeting ID: data004
Level: conversation
Text Length: 231 characters

Text Content:
----------------------------------------------------------------------------------------------------
45](http://www.youtube.com/watch?v=rKpltaOMFdc&t=645)] **Host:** So then you've gone into this Abu Dhabi role, and now you're in this entrepreneurial freelancing. What have been the biggest things you've learned in that transition?
----------------------------------------------------------------------------------------------------


[CHUNK #23]
Chunk ID: data004_conv_14
Meeting ID: data004
Level: conversation
Text Length: 1333 characters

Text Content:
----------------------------------------------------------------------------------------------------
06](http://www.youtube.com/watch?v=rKpltaOMFdc&t=666)] **Nimi Mehta:** I did radio in Abu Dhabi for a year, until **Channel 4 poached me over to Dubai**. I was at Channel 4 hosting the breakfast show for five years. We were named the number one show in the country. The power of **visualization and manifestation is real**. I cannot stress it enough; it is one of the key things that got me to where I am today. I remember sitting there in my bed when I was unemployed and miserable, looking at the Channel 4 presenter lineup, just staring and visualizing myself in that lineup. And I kept saying, "You're going to be there." It happened literally a few years later. That was my dream job. I was lucky that my co-host and I had a 50/50 share, rather than the classic radio setup where females were "giggle girls." But it got to a point where I felt it in my bones: "It is time for a change." The question I asked myself was: **"Which fear do I choose?"** The first fear was leaving my solid salary, comfort zone, and letting go of my "dream." The second fear was, **"Are you still going to be here in five years time, feeling undervalued and miserable?"** That fear outweighed the fear before. I was so scared of staying stagnant that the fear about leaving was irrelevant. I would rather look back and say, "I'm so proud you tried."
----------------------------------------------------------------------------------------------------


[CHUNK #24]
Chunk ID: data004_conv_15
Meeting ID: data004
Level: conversation
Text Length: 547 characters

Text Content:
----------------------------------------------------------------------------------------------------
00](http://www.youtube.com/watch?v=rKpltaOMFdc&t=900)] **Host:** That is such a powerful question. A similar question is: **Which discomfort do you want to choose?** It's uncomfortable not pursuing things you dream about, and it's also uncomfortable pursuing them because you deal with self-doubt and uncertainty. But the flip is never trying and being stuck in something that is not setting your heart on fire. If you get that feeling in your bones, you have to acknowledge what's going on. Getting raw with yourself is the most actionable thing.
----------------------------------------------------------------------------------------------------


[CHUNK #25]
Chunk ID: data004_conv_16
Meeting ID: data004
Level: conversation
Text Length: 612 characters

Text Content:
----------------------------------------------------------------------------------------------------
18](http://www.youtube.com/watch?v=rKpltaOMFdc&t=978)] **Nimi Mehta:** 100%. Your **body tells you exactly what you want**. We talk about listening to our mind and heart, but our body is so aligned. I have a **5-second rule**: as soon as I feel something, I hold on to that, because in five seconds, my mind's going to start convincing me otherwise. It will bring up money, stability, and all the extras that don't contribute to your core. Hold on to that core gut feeling. A lot of us ignore it because it's the easiest thing to do. That kind of discipline has really changed the game for me in decision making.
----------------------------------------------------------------------------------------------------


[CHUNK #26]
Chunk ID: data004_conv_17
Meeting ID: data004
Level: conversation
Text Length: 564 characters

Text Content:
----------------------------------------------------------------------------------------------------
41](http://www.youtube.com/watch?v=rKpltaOMFdc&t=1061)] **Host:** That's amazing. Sitting with the thought for five seconds and just noticing that knee-jerk reaction is a good actionable thing people can practice to start listening to that inner voice. My fiancé, a former chiropractor, used to talk about how the body's language was **pain**. For me, if I'm stressed or out of alignment, I always get neck pain. I think just tuning into little things, whether it's in moments of stress or change, getting familiar with how you respond in your body is so powerful.
----------------------------------------------------------------------------------------------------


[CHUNK #27]
Chunk ID: data004_conv_18
Meeting ID: data004
Level: conversation
Text Length: 455 characters

Text Content:
----------------------------------------------------------------------------------------------------
35](http://www.youtube.com/watch?v=rKpltaOMFdc&t=1175)] **Nimi Mehta:** That also applies to when you meet people. My body instantly tells me if I am the vibe for that person or not. Usually, even when my body tells me they're not my vibe, I start doubting myself rather than doubting the other person. We need to trust ourselves more. We get into bad friendships or relationships because we are not following our gut. That level of self-awareness is key.
----------------------------------------------------------------------------------------------------


[CHUNK #28]
Chunk ID: data004_conv_19
Meeting ID: data004
Level: conversation
Text Length: 412 characters

Text Content:
----------------------------------------------------------------------------------------------------
21](http://www.youtube.com/watch?v=rKpltaOMFdc&t=1221)] **Host:** One thing that helped me get comfortable with that is realizing it's not about good or bad, it's just **alignment**. Our energies are just not aligned, and I don't need to give you more than what I have to. I'd love to ask you about **finding your voice**. What does that actually mean? How do people go about locating what that even is for them?
----------------------------------------------------------------------------------------------------


[CHUNK #29]
Chunk ID: data004_conv_20
Meeting ID: data004
Level: conversation
Text Length: 746 characters

Text Content:
----------------------------------------------------------------------------------------------------
30](http://www.youtube.com/watch?v=rKpltaOMFdc&t=1290)] **Nimi Mehta:** It started when I shifted from my radio job to **legacy mode**: "What am I leaving behind?" I thought about how I used to be an absolute mute as a child, and now I'm a presenter. I realized what I had taught myself I could **framework** and teach people to do in less time. That's when I created **The Voice Layer Theory**. When you're born, your parents are the biggest influence. On top of that are teachers, then media, and now millions of voices on social media. All these layers are building on top of us, and our own voice is getting **diluted**. Our voice is its own nucleus and our greatest asset, but we haven't done the groundwork to identify it. I did two things:
----------------------------------------------------------------------------------------------------


[CHUNK #30]
Chunk ID: data004_conv_21
Meeting ID: data004
Level: conversation
Text Length: 316 characters

Text Content:
----------------------------------------------------------------------------------------------------
** I took myself away for a week—a social media detox—and started **questioning everything**. Every decision, thought, and opinion: "Why did I choose that?" That's the only way to break through and realize what the source is. I even had an identity crisis questioning if I did journalism because my mom wanted me to.
----------------------------------------------------------------------------------------------------


[CHUNK #31]
Chunk ID: data004_conv_22
Meeting ID: data004
Level: conversation
Text Length: 400 characters

Text Content:
----------------------------------------------------------------------------------------------------
** I identified the five closest people to me and whether they were a positive influence, enhancing my voice, or dimming it. I had to be cutthroat because I have to **protect my voice at all costs**. As Gary Vee said, "**I found my voice in the trenches of other voices.**" Then you rebuild the voices around you with people who enhance your voice. Finding your voice is an **ever-evolving journey**.
----------------------------------------------------------------------------------------------------


[CHUNK #32]
Chunk ID: data004_conv_23
Meeting ID: data004
Level: conversation
Text Length: 629 characters

Text Content:
----------------------------------------------------------------------------------------------------
53](http://www.youtube.com/watch?v=rKpltaOMFdc&t=1733)] **Host:** That is so powerful. I love the step of critically analyzing, **"Who are those five people?"** and extending that to **"What content am I consuming online?"** This is the ultimate blueprint for alignment in life—to get down to the source of why you have certain beliefs or struggle with setting boundaries. I had a similar experience in Greece for my sister's wedding where I drank more than usual and realized how **detached I was from myself**. My intuition was nowhere to be found. Ever since, I'm hyper-aware that **alcohol disconnects me from my own voice**.
----------------------------------------------------------------------------------------------------


[CHUNK #33]
Chunk ID: data004_conv_24
Meeting ID: data004
Level: conversation
Text Length: 396 characters

Text Content:
----------------------------------------------------------------------------------------------------
00](http://www.youtube.com/watch?v=rKpltaOMFdc&t=1920)] **Nimi Mehta:** I resonate with that because every time I go home and I'm surrounded by people who know the old me, **I regress**. I go back to that little, insecure, timid girl, and then I have to almost relearn myself when I return to Dubai. This shows you should be conscious of the things you consume, whether it's people or substances.
----------------------------------------------------------------------------------------------------


[CHUNK #34]
Chunk ID: data004_conv_25
Meeting ID: data004
Level: conversation
Text Length: 333 characters

Text Content:
----------------------------------------------------------------------------------------------------
57](http://www.youtube.com/watch?v=rKpltaOMFdc&t=2037)] **Host:** I asked you what you'd been ruminating on, and one thing that stood out was the difference between being **nice and being assertive**. I struggled with this as a people pleaser, where I wasn't assertive when I should have stood up for myself. Is there a happy medium?
----------------------------------------------------------------------------------------------------


[CHUNK #35]
Chunk ID: data004_conv_26
Meeting ID: data004
Level: conversation
Text Length: 1160 characters

Text Content:
----------------------------------------------------------------------------------------------------
04](http://www.youtube.com/watch?v=rKpltaOMFdc&t=2104)] **Nimi Mehta:** I had to completely dissolve the idea that my only two options were being nice or being mean. Especially as a woman and entrepreneur, I felt uncomfortable. My parents raised me just to "be a good person." But in the media industry, I struggled, especially when a hairdresser on set told me, "**You need to stop being so nice. You need to be a bit of a bitch around here to be respected**." I realized the people who navigate the industry that way operate from **fear**, not respect. That's not what I want. I've figured out that **you can still be kind, but still be very clear and concise about what it is that you want.** I got muddled thinking I couldn't be clear because I didn't want to be labeled a "Diva" or "difficult," which happens to women so easily. The balance is stopping myself from being a "yes" person. A quality of a highly confident person is the ability to **respond and not react**. Responding means taking your time, not waffling, and treating your **words like gold**. I've learned the hard way that being too nice means people walk all over you and take advantage.
----------------------------------------------------------------------------------------------------


[CHUNK #36]
Chunk ID: data004_conv_27
Meeting ID: data004
Level: conversation
Text Length: 654 characters

Text Content:
----------------------------------------------------------------------------------------------------
42](http://www.youtube.com/watch?v=rKpltaOMFdc&t=2382)] **Host:** Being assertive doesn't mean being mean; it means **communicating your boundaries**. People pleasing is saying "yes" to someone else and "no" to yourself. If you strip down to the source, why do you feel the need to put someone else's comfort above your own? If I had responded to conflict in the moment, it would have been reactive and emotional. Taking my time and responding in a way that's aligned for me feels right. But sometimes that means saying nothing, which is me being too nice. It comes down to **delivery** and ensuring you assert yourself in a way that is authentic to you.
----------------------------------------------------------------------------------------------------


[CHUNK #37]
Chunk ID: data004_conv_28
Meeting ID: data004
Level: conversation
Text Length: 621 characters

Text Content:
----------------------------------------------------------------------------------------------------
22](http://www.youtube.com/watch?v=rKpltaOMFdc&t=2542)] **Nimi Mehta:** It goes back to **"Am I reacting or responding?"** Even in professional settings, we feel pressured to answer straight away. Just **take a beat, take a breath**. Say, "I'm not quite clear on that. Let me get back to you," because **your words have value**. We also need to remember that **relationships are everything**. I never want someone to walk away from an interaction with me and feel horrible. I'm conscious of treating everyone—from crew to director—the same. You want to leave a good impression, but also protect yourself at the same time.
----------------------------------------------------------------------------------------------------


[CHUNK #38]
Chunk ID: data004_conv_29
Meeting ID: data004
Level: conversation
Text Length: 438 characters

Text Content:
----------------------------------------------------------------------------------------------------
18](http://www.youtube.com/watch?v=rKpltaOMFdc&t=2658)] **Host:** When you come across personalities that have that "doggy dog" world attitude, you don't need to match their energy. This is why **finding your own voice** is so important. If you're aligned and centered in your own voice, you just respond authentically. It's all about that **regular check-in**, which I do through spending time alone or meditation. Do you have an outlet?
----------------------------------------------------------------------------------------------------


[CHUNK #39]
Chunk ID: data004_conv_30
Meeting ID: data004
Level: conversation
Text Length: 764 characters

Text Content:
----------------------------------------------------------------------------------------------------
22](http://www.youtube.com/watch?v=rKpltaOMFdc&t=2722)] **Nimi Mehta:** I live in my **notes app** and a lot of **photo albums**. When I'm having doubts, I have a photo album called **My Wins**. I take photos of tiny things to hosting big events. I skim through those photos and say, "**You did that.** No one else did it, you did it." It's my reminder album to see how far I've come. I also talk about **loud confidence versus soft confidence**. The loudest person in the room is not the most confident. I call myself an extrovert-introvert; I'm the most confident in my introvert mode. When I see someone who is super loud, I have compassion for them, because there is something deeper there. We don't have to be the loudest in the room to be the most confident.
----------------------------------------------------------------------------------------------------


[CHUNK #40]
Chunk ID: data004_conv_31
Meeting ID: data004
Level: conversation
Text Length: 524 characters

Text Content:
----------------------------------------------------------------------------------------------------
49](http://www.youtube.com/watch?v=rKpltaOMFdc&t=2869)] **Host:** I have an **Excel sheet**—very corporate of me—with a wins list. Once you know you are filling something out, you start looking for those things to be grateful for or proud of yourself for. That builds your confidence. If you are feeling low in self-confidence, **sit with it**. Don't push yourself through it; **move with it**. I gave myself 24 hours this week to sit with feeling rubbish. You'll feel great tomorrow, and you'll be grateful for the rise up.
----------------------------------------------------------------------------------------------------


[CHUNK #41]
Chunk ID: data004_conv_32
Meeting ID: data004
Level: conversation
Text Length: 433 characters

Text Content:
----------------------------------------------------------------------------------------------------
27](http://www.youtube.com/watch?v=rKpltaOMFdc&t=2967)] **Nimi Mehta:** **Emotions are all temporary**. Nothing lasts forever. Just feel it, let it do its thing. You need the lows, because it's a point of reference for the high moments. Everything serves its purpose. My therapist taught me to have a **cookie jar** (or an album of wins) where you track and look to see what you're proud of yourself for today, this week, this month.
----------------------------------------------------------------------------------------------------


[CHUNK #42]
Chunk ID: data004_conv_33
Meeting ID: data004
Level: conversation
Text Length: 159 characters

Text Content:
----------------------------------------------------------------------------------------------------
35](http://www.youtube.com/watch?v=rKpltaOMFdc&t=3035)] **Host:** I think this is a beautiful place to leave our conversation. Thank you so much for your time.
----------------------------------------------------------------------------------------------------


[CHUNK #43]
Chunk ID: data004_conv_34
Meeting ID: data004
Level: conversation
Text Length: 174 characters

Text Content:
----------------------------------------------------------------------------------------------------
47](http://www.youtube.com/watch?v=rKpltaOMFdc&t=3047)] **Nimi Mehta:** Thank you so much for having me, and I've absolutely loved this conversation. Thank you for your time.
----------------------------------------------------------------------------------------------------



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

>>> MEETING: data006 <<<
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[CHUNK #44]
Chunk ID: data006_conv_0
Meeting ID: data006
Level: conversation
Text Length: 163 characters

Text Content:
----------------------------------------------------------------------------------------------------
# data006
00] Jensen Huang: at some point you have to believe something. We've reinvented Computing as we know it. What is the vision for what you see coming next?
----------------------------------------------------------------------------------------------------


[CHUNK #45]
Chunk ID: data006_conv_1
Meeting ID: data006
Level: conversation
Text Length: 158 characters

Text Content:
----------------------------------------------------------------------------------------------------
09] Jensen Huang: Cleo, everything that moves will be robotic someday, and it will be soon. We invested tens of billions of dollars before it really happened.
----------------------------------------------------------------------------------------------------


[CHUNK #46]
Chunk ID: data006_conv_2
Meeting ID: data006
Level: conversation
Text Length: 372 characters

Text Content:
----------------------------------------------------------------------------------------------------
27] Cleo Abram: That's Jensen Huang, and whether you know it or not, his decisions are shaping your future. He's the CEO of Nvidia, the company that skyrocketed over the past few years to become one of the most valuable companies in the world because they led a fundamental shift in how computers work, unleashing this current explosion of what's possible with technology.
----------------------------------------------------------------------------------------------------


[CHUNK #47]
Chunk ID: data006_conv_3
Meeting ID: data006
Level: conversation
Text Length: 149 characters

Text Content:
----------------------------------------------------------------------------------------------------
48] Jensen Huang: Nvidia's done it again. We found ourselves being one of the most important technology companies in the world, and potentially ever.
----------------------------------------------------------------------------------------------------


[CHUNK #48]
Chunk ID: data006_conv_4
Meeting ID: data006
Level: conversation
Text Length: 620 characters

Text Content:
----------------------------------------------------------------------------------------------------
55] Cleo Abram: A huge amount of the most futuristic tech that you're hearing about in AI and robotics and gaming and self-driving cars and breakthrough medical research relies on new chips and software designed by him and his company. During the dozens of background interviews that I did to prepare for this, what struck me most was how much Jensen Huang has already influenced all of our lives over the last 30 years and how many said it's just the beginning of something even bigger. We all need to know what he's building and why, and most importantly, what he's trying to build next. Welcome to huge conversations.
----------------------------------------------------------------------------------------------------


[CHUNK #49]
Chunk ID: data006_conv_5
Meeting ID: data006
Level: conversation
Text Length: 65 characters

Text Content:
----------------------------------------------------------------------------------------------------
36] Jensen Huang: thank you so much for doing, so happy to do it.
----------------------------------------------------------------------------------------------------


[CHUNK #50]
Chunk ID: data006_conv_6
Meeting ID: data006
Level: conversation
Text Length: 167 characters

Text Content:
----------------------------------------------------------------------------------------------------
39] Cleo Abram: Before we dive in, I wanted to tell you how this interview is going to be a little bit different than other interviews I've seen you do recently. Okay.
----------------------------------------------------------------------------------------------------


[CHUNK #51]
Chunk ID: data006_conv_7
Meeting ID: data006
Level: conversation
Text Length: 94 characters

Text Content:
----------------------------------------------------------------------------------------------------
47] Jensen Huang: I'm not going to ask you any questions about you could ask company finances.
----------------------------------------------------------------------------------------------------


[CHUNK #52]
Chunk ID: data006_conv_8
Meeting ID: data006
Level: conversation
Text Length: 384 characters

Text Content:
----------------------------------------------------------------------------------------------------
49] Cleo Abram: Thank you. I'm not going to ask you questions about your management style or why you don't like one-on-ones. I'm not going to ask you about regulations or politics. I think all of those things are important, but I think that our audience can get them well covered elsewhere. Okay. What we do on Huge If True is we make optimistic explainer videos, and we've covered...
----------------------------------------------------------------------------------------------------


[CHUNK #53]
Chunk ID: data006_conv_9
Meeting ID: data006
Level: conversation
Text Length: 64 characters

Text Content:
----------------------------------------------------------------------------------------------------
12] Jensen Huang: I'm the worst person to be an explainer video.
----------------------------------------------------------------------------------------------------


[CHUNK #54]
Chunk ID: data006_conv_10
Meeting ID: data006
Level: conversation
Text Length: 1499 characters

Text Content:
----------------------------------------------------------------------------------------------------
17] Cleo Abram: I think you might be the best, and I think that's what I'm really hoping that we can do together is make a joint explainer video about how can we actually use technology to make the future better. Yeah. And we do it because we believe that when people see those better Futures, they help build them. So the people that you're going to be talking to are awesome. They are optimists who want to build those better Futures, but because we cover so many different topics, we've covered supersonic planes and quantum computers and particle colliders, it means that millions of people come into every episode without any prior knowledge whatsoever. You might be talking to an expert in their field who doesn't know the difference between a CPU and a GPU, or a 12-year-old who might grow up one day to be you but is just starting to learn. Um, for my part, I've now been preparing for this interview for several months, I've including doing background conversations with many members of your team, but I'm not an engineer, so my goal is to help that audience see the future that you see. So I'm going to ask about three areas. The first is how did we get here? What were the key insights that led to this big fundamental shift in computing that we're in now? The second is what's actually happening right now? How did those insights lead to the world that we're now living in that seems like so much is going on all at once? And the third is what is the vision for what you see coming next?
----------------------------------------------------------------------------------------------------


[CHUNK #55]
Chunk ID: data006_conv_11
Meeting ID: data006
Level: conversation
Text Length: 519 characters

Text Content:
----------------------------------------------------------------------------------------------------
45] Cleo Abram: In order to talk about this big moment we're in with AI, I think we need to go back to video games in the '90s. At the time, I know game developers wanted to create more realistic looking graphics, but the hardware couldn't keep up with all of that necessary math. Nvidia came up with a solution that would change not just games, but computing itself. Could you take us back there and explain what was happening and what were the insights that led you and the Nvidia team to create the first modern GPU?
----------------------------------------------------------------------------------------------------


[CHUNK #56]
Chunk ID: data006_conv_12
Meeting ID: data006
Level: conversation
Text Length: 651 characters

Text Content:
----------------------------------------------------------------------------------------------------
16] Jensen Huang: So in the early '90s when we first started the company, we observed that in a software program, inside it, there are just a few lines of code, maybe 10% of the code does 99% of the processing, and that 99% of the processing could be done in parallel. However, the other 90% of the code has to be done sequentially. It turns out that the proper computer, the perfect computer, is one that could do sequential processing and parallel processing, not just one or the other. That was the big observation, and we set out to build a company to solve computer problems that normal computers can't, and that's really the beginning of Nvidia.
----------------------------------------------------------------------------------------------------


[CHUNK #57]
Chunk ID: data006_conv_13
Meeting ID: data006
Level: conversation
Text Length: 445 characters

Text Content:
----------------------------------------------------------------------------------------------------
01] Cleo Abram: My favorite visual of why a CPU versus a GPU really matters so much is a 15-year-old video on the Nvidia YouTube channel where the MythBusters they use a little robot shooting paintballs one by one to show solving problems one at a time or sequential processing on a CPU, but then they roll out this huge robot that shoots all of the paintballs at once doing smaller problems all at the same time or parallel processing on a GPU.
----------------------------------------------------------------------------------------------------


[CHUNK #58]
Chunk ID: data006_conv_14
Meeting ID: data006
Level: conversation
Text Length: 90 characters

Text Content:
----------------------------------------------------------------------------------------------------
33] Cleo Abram: So Nvidia unlocks all of this new power for video games. Why gaming first?
----------------------------------------------------------------------------------------------------


[CHUNK #59]
Chunk ID: data006_conv_15
Meeting ID: data006
Level: conversation
Text Length: 795 characters

Text Content:
----------------------------------------------------------------------------------------------------
38] Jensen Huang: The video games uh requires parallel processing for uh processing 3D graphics, and we chose video games because one, we loved the application. It's a simulation of virtual worlds, and who doesn't want to go to virtual worlds? And, and we had the good observation that video games has potential to be the largest market for for entertainment ever, and it turned out to be true. And having it being a large market is important because the technology is complicated, and if we had a large market, our R&D budget could be large. We could create new technology, and that flywheel between technology and market and greater technology was was really the flywheel that got Nvidia to become one of the most important technology companies in the world. It was all because of video games.
----------------------------------------------------------------------------------------------------


[CHUNK #60]
Chunk ID: data006_conv_16
Meeting ID: data006
Level: conversation
Text Length: 123 characters

Text Content:
----------------------------------------------------------------------------------------------------
24] Cleo Abram: I've heard you say that GPUs were a time machine. Yeah. Could you tell me more about what you mean by that?
----------------------------------------------------------------------------------------------------


[CHUNK #61]
Chunk ID: data006_conv_17
Meeting ID: data006
Level: conversation
Text Length: 715 characters

Text Content:
----------------------------------------------------------------------------------------------------
29] Jensen Huang: A GPU is like a time machine because it lets you see the future sooner. One of the most amazing things anybody's ever said to me was a uh quantum chemistry scientist. He said, "Jensen, because of Nvidia's work, I can do my life's work in my lifetime." That's time travel. He was able to do something that was beyond his lifetime within his lifetime, and and this is because we make applications run so much faster, and you get to see the future. And so when you're doing weather prediction, for example, you're seeing the future. When you're doing a a simulation, a virtual city with virtual traffic, and we're um simulating our self-driving car through that virtual city, we're doing time travel.
----------------------------------------------------------------------------------------------------


[CHUNK #62]
Chunk ID: data006_conv_18
Meeting ID: data006
Level: conversation
Text Length: 644 characters

Text Content:
----------------------------------------------------------------------------------------------------
18] Cleo Abram: So parallel processing takes off in gaming, and it's allowing us to create worlds in computers that we never could have before. And and gaming is sort of this this first incredible case of parallel processing unlocking a lot more power. And then, as you said, people begin to use that power across many different industries. The case of the of the quantum chemistry researcher, when I've heard you tell that story, it's that he was running molecular simulations in a way where it was much faster to run in parallel on Nvidia GPUs even then than it was to run them on the supercomputer with the CPU that he had been using before.
----------------------------------------------------------------------------------------------------


[CHUNK #63]
Chunk ID: data006_conv_19
Meeting ID: data006
Level: conversation
Text Length: 42 characters

Text Content:
----------------------------------------------------------------------------------------------------
56] Jensen Huang: Yeah, that's true. So...
----------------------------------------------------------------------------------------------------


[CHUNK #64]
Chunk ID: data006_conv_20
Meeting ID: data006
Level: conversation
Text Length: 86 characters

Text Content:
----------------------------------------------------------------------------------------------------
58] Cleo Abram: Oh my god, it's revolutionizing all of these other industries as well.
----------------------------------------------------------------------------------------------------


[CHUNK #65]
Chunk ID: data006_conv_21
Meeting ID: data006
Level: conversation
Text Length: 346 characters

Text Content:
----------------------------------------------------------------------------------------------------
01] Cleo Abram: MH. It's beginning to change how we see what's possible with computers. And my understanding is that in the early 2000s, you see this and you realize that actually doing that is a little bit difficult because what that researcher had to do is he had to sort of trick the GPUs into thinking that his problem was a graphics problem.
----------------------------------------------------------------------------------------------------


[CHUNK #66]
Chunk ID: data006_conv_22
Meeting ID: data006
Level: conversation
Text Length: 84 characters

Text Content:
----------------------------------------------------------------------------------------------------
24] Jensen Huang: That's exactly right. No, that's very good. You did some research.
----------------------------------------------------------------------------------------------------


[CHUNK #67]
Chunk ID: data006_conv_23
Meeting ID: data006
Level: conversation
Text Length: 393 characters

Text Content:
----------------------------------------------------------------------------------------------------
28] Cleo Abram: So you create a way to make that a lot easier. That's right. Specifically, it's a platform called Cuda, which lets programmers tell the GPU what to do using programming languages that they already know like C. And that's a big deal because it gives way more people easier access to all of this computing power. Could you explain what the vision was that led you to create Cuda?
----------------------------------------------------------------------------------------------------


[CHUNK #68]
Chunk ID: data006_conv_24
Meeting ID: data006
Level: conversation
Text Length: 1893 characters

Text Content:
----------------------------------------------------------------------------------------------------
46] Jensen Huang: Partly uh researchers uh discovering it, partly internal uh inspiration, and um uh and partly solving a problem. And you know, a lot of interesting interesting ideas come out of that soup, you know. Some of it is is aspiration and inspiration, some of it is just desperation, you know. And, and so in, in the case of Cuda, it's very much this the same way. And um, probably the first external ideas of using our GPUs for parallel processing emerged out of some interesting work in medical imaging. A couple of researchers at Mass General were using it uh to do uh CT reconstruction. They were using our graphics process for that reason, and it inspired us. Meanwhile, the problem that we're trying to solve inside our company has to do with the fact that when you're trying to create these virtual worlds for video games, you would like it to be beautiful but also dynamic. Water should flow like water, and explosions should be like explosions. So there's particle physics you want to do, fluid dynamics you want to do, and uh that is much harder to do if your pipeline is only able to do computer graphics. And so we have a natural reason to want to do it in, in the the the market that we were serving. So researchers were also um horsing around with using our GPUs for general purpose uh acceleration, and and so there there are multiple multiple factors that were coming together in that soup. Uh we just when the time came and uh uh we decided to to uh do something proper and create a Cuda as a result of that. Fundamentally, the reason why why I was certain that Cuda was going to be successful, and we, we put the whole company behind it, was because fundamentally, uh our GPU was going to be the highest volume parallel processors built in the world because the market of video games was so large, and so this architecture has a good chance of reaching many people.
----------------------------------------------------------------------------------------------------


[CHUNK #69]
Chunk ID: data006_conv_25
Meeting ID: data006
Level: conversation
Text Length: 289 characters

Text Content:
----------------------------------------------------------------------------------------------------
45] Cleo Abram: It has seemed to me like creating Cuda was this incredibly optimistic, huge if true thing to do, where you were saying, if we create a way for many more people to use much more computing power, they might create incredible things. And then of course it came true. They did.
----------------------------------------------------------------------------------------------------


[CHUNK #70]
Chunk ID: data006_conv_26
Meeting ID: data006
Level: conversation
Text Length: 1053 characters

Text Content:
----------------------------------------------------------------------------------------------------
03] Cleo Abram: In 2012, a group of three researchers submits an entry to a famous competition where the goal is to create computer systems that could recognize images and label them with categories. And their entry just crushes the competition. It gets way fewer answers wrong. It was incredible. It blows everyone away. It's called AlexNet, and it's a kind of AI called the neural network. My understanding is one reason it was so good is that they used a huge amount of data to train that system, and they did it on Nvidia GPUs. All of a sudden, GPUs weren't just a way to make computers faster and more efficient. They're becoming the engines of a whole new way of computing. We're moving from instructing computers with step-by-step directions to training computers to learn by showing them a huge number of examples. This moment in 2012 really kicked off this truly seismic shift that we're all seeing with AI right now. Could you describe what that moment was like from your perspective, and what did you see it would mean for all of our futures?
----------------------------------------------------------------------------------------------------


[CHUNK #71]
Chunk ID: data006_conv_27
Meeting ID: data006
Level: conversation
Text Length: 2960 characters

Text Content:
----------------------------------------------------------------------------------------------------
06] Jensen Huang: When you create something new like Cuda, if you build it, they might not come. And and that's that's always the the cynic perspective. However, the optimist perspective would say, but if you don't build it, they can't come. And that's usually how we look at the world, you know. We, we have to reason about intuitively why this would be very useful. And in fact, uh, in 2012, Ilya Sutskever and Alex Krizhevsky and Jeff Hinton in the University of Toronto, the lab that they were at, they reached out to a GeForce GTX 580 because they learned about Cuda and that Cuda might be able to, to be used as a parallel processor for training AlexNet. And uh, so our inspiration that GeForce could be the the vehicle to bring out this parallel architecture into the world and that researchers would somehow find it someday was a good, was a good strategy. It was a strategy based on hope, um, but it was also reasoned hope. The, the thing that really caught our attention was simultaneously we were trying to solve the computer vision problem inside the company, and we were trying to get Cuda to uh be a good computer vision uh processor, and we were frustrated by by uh a whole bunch of early developments internally with respect to our our um computer vision effort and getting Cuda to be able to do it. And all of a sudden, we saw AlexNet, um, this new algorithm that that is uh completely different than computer vision algorithms before it, uh take a giant leap in terms of capability for computer vision. And when we saw that, it was partly out of interest, but partly because we were struggling with something ourselves. And so we were, we were highly interested to want to see it work. And so when we, when we looked at AlexNet, we were inspired by that. Um, but the big breakthrough, I would say, uh, is when we, when we saw AlexNet, we asked ourselves, you know, how far can AlexNet go? If it can do this with computer vision, how far can it go? And if it, if it could go to the limits of what we think it could go, um, the type of problems it could solve, what would it mean for the computer industry and what would it mean for the computer architecture? And we were, we were um, uh, we rightfully reasoned that if machine learning, if the deep learning architecture can scale, uh, the vast majority of machine learning problems could be represented with deep neural networks, and the type of problems we could solve with machine learning is so vast that it has the potential of reshaping the computer industry altogether. And which prompted us to uh re-engineer the entire computing stack, which is where uh DGX came from. And this little baby DGX sitting here, um, uh, all of this came from, from that observation that we ought to reinvent the entire computing stack layer by layer by layer. You know, computers after 65 years since uh IBM System/360 introduced modern general purpose computing, we've reinvented computing as we know it.
----------------------------------------------------------------------------------------------------


[CHUNK #72]
Chunk ID: data006_conv_28
Meeting ID: data006
Level: conversation
Text Length: 470 characters

Text Content:
----------------------------------------------------------------------------------------------------
11] Cleo Abram: To think about this as a whole story, so parallel processing reinvents modern gaming and revolutionizes an entire industry. Then that way of computing, that parallel processing, begins to be used across different industries. You invest in that by building Cuda, and then Cuda and the use of GPUs allows for a a step change in neural networks and machine learning and begins a sort of revolution that we're now seeing uh only increase in importance today.
----------------------------------------------------------------------------------------------------


[CHUNK #73]
Chunk ID: data006_conv_29
Meeting ID: data006
Level: conversation
Text Length: 414 characters

Text Content:
----------------------------------------------------------------------------------------------------
43] Jensen Huang: All of a sudden, computer vision is solved. All of a sudden, speech recognition is solved. All of a sudden, language understanding is solved. These incredible problems associated with intelligence one by one by one by one, where we had no solutions for in past desperate desire to have solutions for, all of a sudden one after another get solved, you know, every couple of years. It's incredible.
----------------------------------------------------------------------------------------------------


[CHUNK #74]
Chunk ID: data006_conv_30
Meeting ID: data006
Level: conversation
Text Length: 363 characters

Text Content:
----------------------------------------------------------------------------------------------------
04] Cleo Abram: Yeah. So you're seeing that in 2012, you're looking ahead and and believing that that's the future that you're going to be living in now, and you're making bets that get you there. Really big bets that have very high stakes. And then my perception as a lay person is that it takes a pretty long time to get there. You make these best. Eight years.
----------------------------------------------------------------------------------------------------


[CHUNK #75]
Chunk ID: data006_conv_31
Meeting ID: data006
Level: conversation
Text Length: 299 characters

Text Content:
----------------------------------------------------------------------------------------------------
29] Cleo Abram: So my question is, if AlexNet happened in 2012 and this audience is probably seeing and hearing so much more about AI and Nvidia specifically 10 years later, why did it take a decade? And also, because you would place those bets, what did the middle of that decade feel like for you?
----------------------------------------------------------------------------------------------------


[CHUNK #76]
Chunk ID: data006_conv_32
Meeting ID: data006
Level: conversation
Text Length: 2534 characters

Text Content:
----------------------------------------------------------------------------------------------------
49] Jensen Huang: Well, that's a good question. It probably felt like today, you know. To me, to me there's always some problem and then there's there's some reason to be to be impatient. There's always some reason to be uh happy about where you are and and there's always many reasons to carry on. And so, so I I think as I was reflecting a second ago, that sounds like this morning. So, but I would say that in all things that we pursue, first you have to have core beliefs. You have to reason from, from your best principles, um, and ideally you're reasoning from it from principles of either physics or uh deep understanding of of uh of the industry or deep understanding of the science. Wherever you're reasoning from, um, you reason from first principles and at some point you have to believe something. And if those principles don't change and the assumptions don't change, uh then you there's no reason to change your core beliefs. And then along the way, there's always some uh evidence of of um, you know, of success and and that you're you're leading in the right direction. And sometimes, you know, you go a long time without evidence of success, and you might have to course correct a little, but um, the evidence comes. And and if you feel like you're going in the right direction, we just keep on going. The question of why did we stay so committed for so long? The answer is actually the opposite. There was no reason to not be committed because we are we believed it, and and um, I've believed in Nvidia for 30 plus years, and and I'm still here working every single day. And uh there's no fundamental reason for me to change my belief system, and um uh I fundamentally believe that that the work we're doing in revolutionizing computing is as true today, even more true today than it was before. And and um, uh, and so we'll, we'll stick with it, you know, until until otherwise. Um, there's of course very difficult times along the way, you know, when you're investing in something and nobody else believes in it and cost a lot of money and uh, you know, maybe investors or or others would rather you just keep the profit or, you know, whatever it is, improve the share price or whatever it is, um, but you have to believe in your future. You have to invest in yourself, and and um, uh, we believed this so deeply uh that that we we invested, you know, tens of billions of dollars uh before before it really happened. And um, uh, yeah, it, it was, it was 10 long years, but it was, it was, it was fun along the way.
----------------------------------------------------------------------------------------------------


[CHUNK #77]
Chunk ID: data006_conv_33
Meeting ID: data006
Level: conversation
Text Length: 303 characters

Text Content:
----------------------------------------------------------------------------------------------------
32] Cleo Abram: How would you summarize those core beliefs? What is it that you believe about the way computers should work and what they can do for us that keeps you not only coming through that decade, but also doing what you're doing now, making bets, I'm sure you're making for the next few decades?
----------------------------------------------------------------------------------------------------


[CHUNK #78]
Chunk ID: data006_conv_34
Meeting ID: data006
Level: conversation
Text Length: 2687 characters

Text Content:
----------------------------------------------------------------------------------------------------
49] Jensen Huang: The first core belief uh was our first discussion was about accelerated computing, parallel computing versus versus general purpose computing. We would add uh two of those processors together, and we would do accelerated computing, and I continue to believe that today. The second was was the recognition that these deep learning networks, these DNNs that came to the public during 2012, these deep neural networks have the ability to learn patterns and relationships from a whole bunch of different types of data, and that it can learn more and more uh nuanced features if it could be larger and larger. And it's easier to make them larger and larger, make them deeper and deeper, um, or wider and wider. And so the scalability of the architecture is, is um, uh, empirically true. Uh, the uh, the fact that model size and the data size being larger and larger can learn more knowledge uh is also true, uh empirically true. And so, uh, if that's the case, uh, you could, you know, what, what are the limits there? Not unless there's a physical limit or an architectural limit or mathematical limit, and it was never found. And so we believe that you could scale it. Then the question, the only other question is, what can you learn from data? What can you learn from experience? Data is basically digital versions of human experience. And so what can you learn? Uh, you obviously can learn object recognition from images, you can learn speech from just listening to sound, you can learn uh even languages and vocabulary and syntax and grammar, and all just by studying a whole bunch of letters and words. So we've now demonstrated that AI or deep learning has the ability to learn almost any modality of data and it can translate to any modality of data. And so what does that mean? You can go from text to text, right? Summarize a paragraph. You can go from text to text, translate from language to language. You can go from text to images, that's image generation. You can go from images to text, that's captioning. You can even go from amino acid sequences to protein structures. In the future, you'll go from protein to words. What does this protein do? Or um, give me an example of a protein that has these properties, you know, uh, identifying a drug target. Um, and so you could just see that all of these problems are around the corner to be solved. Uh, you can go from words to video. Why can't you go from words to action tokens for a robot? You know, from the computer's perspective, how is it any different? And so it, it opened up this universe of opportunities and universe of problems that we can go solve, and um, that, that, that gets us quite excited.
----------------------------------------------------------------------------------------------------


[CHUNK #79]
Chunk ID: data006_conv_35
Meeting ID: data006
Level: conversation
Text Length: 306 characters

Text Content:
----------------------------------------------------------------------------------------------------
47] Cleo Abram: It feels like we are on the cusp of This truly enormous change. When I think about the next 10 years, I unlike the last 10 years, I know we've gone through a lot of change already, but I don't think I can predict anymore how I will be using the technology that is currently being developed.
----------------------------------------------------------------------------------------------------


[CHUNK #80]
Chunk ID: data006_conv_36
Meeting ID: data006
Level: conversation
Text Length: 702 characters

Text Content:
----------------------------------------------------------------------------------------------------
06] Jensen Huang: That's exactly right. I think the last 10, the reason why you feel that way is the last 10 years was really about the science of AI. The next 10 years, we're going to have plenty of Science of AI, but the next 10 years is going to be the application science of AI. The fundamental science versus the application science. And so the, the applied research, the application side of AI now becomes, how can I apply AI to digital biology? How can I apply AI to climate technology? How can I apply AI to agriculture, to fishery, to robotics, to transportation, um, optimizing logistics? How can I apply AI to, you know, teaching? How do I apply AI to, you know, podcasting? Right? And so...
----------------------------------------------------------------------------------------------------


[CHUNK #81]
Chunk ID: data006_conv_37
Meeting ID: data006
Level: conversation
Text Length: 312 characters

Text Content:
----------------------------------------------------------------------------------------------------
50] Cleo Abram: Right. And so I'd love to choose a couple of those to help people see how this fundamental change in computing that we've been talking about is actually going to change their experience of their lives, how they're actually going to use technology that is based on everything we just talked about.
----------------------------------------------------------------------------------------------------


[CHUNK #82]
Chunk ID: data006_conv_38
Meeting ID: data006
Level: conversation
Text Length: 1156 characters

Text Content:
----------------------------------------------------------------------------------------------------
04] Cleo Abram: One of the things that I've now heard you talk a lot about, and I'm have a particular interest in, is physical AI, or in other words, robots. My friends, meaning humanoid robots, but also robots like self-driving cars and smart buildings or autonomous warehouses or autonomous lawnmowers or more. From what I understand, we might be about to see a huge leap in what all of these robots are capable of because we're changing how we train them. Up until recently, you've either had to train your robot in the real world where it could get damaged or wear down, or you could get data from fairly limited sources like humans in motion capture suits, but that means that robots aren't getting as many examples as they'd need to learn more quickly. But now we're starting to train robots in digital worlds, which means way more repetitions a day, way more conditions, learning way faster. So we could be in a big bang moment for robots right now, and Nvidia is building tools to make that happen. You have Omniverse, and my understanding is this is 3D worlds that help train robotic systems so that they don't need to train in the physical world.
----------------------------------------------------------------------------------------------------


[CHUNK #83]
Chunk ID: data006_conv_39
Meeting ID: data006
Level: conversation
Text Length: 39 characters

Text Content:
----------------------------------------------------------------------------------------------------
26] Jensen Huang: That's exactly right.
----------------------------------------------------------------------------------------------------


[CHUNK #84]
Chunk ID: data006_conv_40
Meeting ID: data006
Level: conversation
Text Length: 382 characters

Text Content:
----------------------------------------------------------------------------------------------------
27] Cleo Abram: You just just announced Cosmos, which is ways to make that 3D universe much more realistic, so you can get all kinds of different, um, if we're training something on this table, many different kinds of lighting on the table, many different times of day, many different, you know, experiences for the robot to go through so that it can get even more out of Omniverse.
----------------------------------------------------------------------------------------------------


[CHUNK #85]
Chunk ID: data006_conv_41
Meeting ID: data006
Level: conversation
Text Length: 228 characters

Text Content:
----------------------------------------------------------------------------------------------------
54] Cleo Abram: As a kid who grew up loving data on Star Trek, Isaac Asimov's book, and just dreaming about a future with robots, how do we get from the robots that we have now to the future world that you see of robotics? Yeah.
----------------------------------------------------------------------------------------------------


[CHUNK #86]
Chunk ID: data006_conv_42
Meeting ID: data006
Level: conversation
Text Length: 2990 characters

Text Content:
----------------------------------------------------------------------------------------------------
11] Jensen Huang: Let me use um language models, maybe Chat GPT, as a reference for understanding um Omniverse and Cosmos. And so, so first of all, when Chat GPT first came out, it it was it was um extraordinary, and it has the ability to do uh to basically uh from your prompt uh generate text. However, as amazing as it was, it has um the tendency to hallucinate. Uh, if it goes on too long or if uh it pontificates about a topic it, you know, is not informed about, it'll still do a good job generating plausible answers. Um, it just wasn't grounded in the truth. And so, so um, uh, people people uh called it hallucination. And so the next generation uh shortly it was, it had the ability to be conditioned by um context. So you could upload your PDF and now it's grounded by the PDF. The PDF becomes the ground truth. It could be it could actually look up search, and then the search becomes uh its ground truth. And between that, it could reason about uh what is how to produce the answer that you're asking for. And so, so the first part is a generative AI, and the second part is ground truth. Okay. And so now let's come into the the the the physical world, uh the world model. We need a foundation model just like we need Chat GPT had a core foundation model that was the breakthrough. In order for robotics to to be smart about the physical world, it has to understand things like gravity, friction, inertia, um, geometric and spatial awareness. It has to uh understand that an object is sitting there, even when I looked away, when I come back it's still sitting there, object permanence. Um, it has to understand cause and effect. If I tip it, it'll fall over. Um, and so, so these kind of physical common sense, if you will, has to be captured or encoded into a world foundation model so that the AI has world common sense. Okay. And so, so we have to goes somebody has to go create that, and that's what we did with Cosmos. We created a world language model just like Chat GPT was a language model, this is a world model. The second thing we have to go do is we have to do the same thing that we did with PDFs and context and um grounding it with ground truth. And so the way we augment Cosmos with ground truth is with physical simulations because Omniverse uses physics simulation, which is based on principled solvers. The, the mathematics is Newtonian physics is the right, it's the math we know. Okay. All of the the fundamental laws of physics uh we've understood for a very long time, and it's encoded into, captured into Omniverse, that's why Omniverse is a simulator. And using the simulator to ground or to condition Cosmos, we can now generate an infinite number of stories of the future, and they're grounded on physical truth. Just like between PDF or search plus Chat GPT, we can generate an infinite amount of interesting things, answer a whole bunch of interesting questions. The combination of Omniverse plus Cosmos, you could do that for the physical world.
----------------------------------------------------------------------------------------------------


[CHUNK #87]
Chunk ID: data006_conv_43
Meeting ID: data006
Level: conversation
Text Length: 685 characters

Text Content:
----------------------------------------------------------------------------------------------------
41] Cleo Abram: So to illustrate this for the audience, if you had a robot in a factory and you wanted to make it learn every route that it could take, instead of manually going through all of those routes, which could take days and could be a lot of wear and tear on the robot, we're now able to simulate all of them digitally in a fraction of the time and in many different situations that the robot might face. It's dark, it's blocked, it's et cetera. So the robot is now learning much, much faster. It seems to me like the future might look very different than today if you play this out 10 years. How do you see people actually interacting with this technology in the near future?
----------------------------------------------------------------------------------------------------


[CHUNK #88]
Chunk ID: data006_conv_44
Meeting ID: data006
Level: conversation
Text Length: 1525 characters

Text Content:
----------------------------------------------------------------------------------------------------
20] Jensen Huang: Cleo, everything that moves will be robotic someday, and it will be soon. You know, the, the idea that we'll be pushing around a lawn mower is already kind of silly, you know. Maybe people do it because because it's fun, but, but there's no need to. And and um uh every car is going to be robotic. Human robots. Uh the technology necessary to make it possible uh is just around the corner. And so everything that moves will be robotic. And they'll they'll learn how to be a robot in Omniverse Cosmos, and will generate all these plausible, physically plausible futures, and the the robots will learn from them, and then they'll come into the physical world. And you know, it's exactly the same. A future where um, well, you're just surrounded by robots is for certain. And I'm just excited about having my own R2-D2. And of course, R2-D2 wouldn't be quite the can that it is and roll roll around. It'll be, you know, R2-D2. Yeah. It'll probably be a different physical embodiment. Um, but it's always R2, you know. So my R2 is going to go around with me. Sometimes it's in my smart glasses, sometimes it's in my phone, sometimes it's in my PC, um, it's in my car. So R2 is with me all the time, including, you know, when I get home, you know, where I left a physical version of R2, and you know, whatever, whatever that version happens to be, you know, we, we'll interact with R2. And so I think the idea that we'll have our own R2-D2 for our entire life and it grows up with us, um, that's a certainty now.
----------------------------------------------------------------------------------------------------


[CHUNK #89]
Chunk ID: data006_conv_45
Meeting ID: data006
Level: conversation
Text Length: 182 characters

Text Content:
----------------------------------------------------------------------------------------------------
04] Cleo Abram: Yeah, I think a lot of news media when they talk about futures like this, they focus on what could go wrong. And that makes sense. There is a lot that could go wrong.
----------------------------------------------------------------------------------------------------


[CHUNK #90]
Chunk ID: data006_conv_46
Meeting ID: data006
Level: conversation
Text Length: 107 characters

Text Content:
----------------------------------------------------------------------------------------------------
13] Jensen Huang: We should talk about what could go wrong so we could keep it from from going wrong. Yeah.
----------------------------------------------------------------------------------------------------


[CHUNK #91]
Chunk ID: data006_conv_47
Meeting ID: data006
Level: conversation
Text Length: 135 characters

Text Content:
----------------------------------------------------------------------------------------------------
15] Cleo Abram: That's the approach that we like to take on the show is what are the big challenges so that we can overcome them. Yeah.
----------------------------------------------------------------------------------------------------


[CHUNK #92]
Chunk ID: data006_conv_48
Meeting ID: data006
Level: conversation
Text Length: 87 characters

Text Content:
----------------------------------------------------------------------------------------------------
23] Cleo Abram: What buckets do you think about when you're worrying about this future?
----------------------------------------------------------------------------------------------------


[CHUNK #93]
Chunk ID: data006_conv_49
Meeting ID: data006
Level: conversation
Text Length: 2541 characters

Text Content:
----------------------------------------------------------------------------------------------------
26] Jensen Huang: Well, there's, there's a whole bunch of the stuff that everybody talks about: bias or toxicity or or just hallucination. Um, you know, speaking with great confidence about something it knows nothing about and as a result we rely on that information. Um, uh, generating, that's a version of generating uh fake information, fake fake news or fake images or whatever it is. Of course, impersonation. Um, it, it does such a good job um pretending to be a human, it could be it could do an incredibly good job pretending to be a specific human. And so, so the, the um, uh, the the spectrum of of um areas we have to be concerned about uh is fairly clear, and there's a lot of, there's a lot of people who are working on it. There's, there's a some of the stuff some of the stuff related to AI safety um requires deep research and deep deep engineering, and that's simply it wants to do the right thing, it just didn't perform it right, and as a result hurt somebody. You know, for example, uh self-driving car that wants to drive nicely and and drive properly, and just somehow the sensor broke down or or uh it didn't detect something or um, you know, made a too too aggressive turn or whatever it is, it did it poorly. It did it wrong, wrongly. And so that's that's a whole bunch of engineering that has to be done to to make sure that AI safety is upheld by making sure that the product function properly. And then, and then lastly, you know, whatever, what happens if the s the the AI wants to do a good job, but the system failed? Meaning the AI wanted to stop, um, stop stop something from happening, and it turned out just when it wanted to do it, um, the machine broke down. And so this is no different than than a flight computer inside a plane having three versions of them and then uh, so there's there's triple redundancy inside the system, inside autopilots, and then you have two pilots, and then you have um, uh, air traffic control, and then you have other pilots watching out for these P pilots. And so, so that the AI safety systems has to be architected as a community such that such that these AIs uh, one um uh, work work function function properly, when they don't function properly, they don't put people in harm's way, and that they're sufficiently safety and security systems all around them uh to make sure that that um uh we keep AI safe. And so there's this spectrum of conversation is gigantic, and and um uh, you know, we have to take the parts take the parts apart and and build them as engineers.
----------------------------------------------------------------------------------------------------


[CHUNK #94]
Chunk ID: data006_conv_50
Meeting ID: data006
Level: conversation
Text Length: 560 characters

Text Content:
----------------------------------------------------------------------------------------------------
10] Cleo Abram: One of the incredible things about this moment that we're in right now is that we no longer have a lot of the technological limits that we had in a world of CPUs and sequential processing, and we've unlocked not only a new way to do computing and and but also a way to continue to improve. Parallel processing has a a different kind of physics to it than the improvements that we were able to make on CPUs. I'm curious, what are the scientific or technological limitations that we face now in the current world that you're thinking a lot about?
----------------------------------------------------------------------------------------------------


[CHUNK #95]
Chunk ID: data006_conv_51
Meeting ID: data006
Level: conversation
Text Length: 693 characters

Text Content:
----------------------------------------------------------------------------------------------------
47] Jensen Huang: Well, everything in the end is about how much work you can get done within the limitations of the energy that you have. And so, so that that's a that's a physical limit, and uh the laws of physics uh about transporting s information and um transporting bits, flipping bits and transporting bits, um at the end of the day the energy it takes to do that um limits what we can get done, and the amount of energy that we have limits what we can get done. We're far from having any fundamental limits that keep us from advancing. In the meantime, we seek to build better and more energy efficient computers. This this little computer, uh the the big version of it was uh $250,000.
----------------------------------------------------------------------------------------------------


[CHUNK #96]
Chunk ID: data006_conv_52
Meeting ID: data006
Level: conversation
Text Length: 65 characters

Text Content:
----------------------------------------------------------------------------------------------------
38] Cleo Abram: Pick up. Yeah. Yeah. That's little baby baby DGX.
----------------------------------------------------------------------------------------------------


[CHUNK #97]
Chunk ID: data006_conv_53
Meeting ID: data006
Level: conversation
Text Length: 348 characters

Text Content:
----------------------------------------------------------------------------------------------------
40] Jensen Huang: Yeah. This is an AI supercomputer. The version that I delivered, this is just a prototype, so it's a mockup. And so the the the very first version was DGX-1. I delivered to Open AI in 2016, and that was $250,000, 10,000 times more power, more energy necessary uh than this version, and this version has six times more performance.
----------------------------------------------------------------------------------------------------


[CHUNK #98]
Chunk ID: data006_conv_54
Meeting ID: data006
Level: conversation
Text Length: 45 characters

Text Content:
----------------------------------------------------------------------------------------------------
07] Cleo Abram: Wow. I know. It's incredible.
----------------------------------------------------------------------------------------------------


[CHUNK #99]
Chunk ID: data006_conv_55
Meeting ID: data006
Level: conversation
Text Length: 823 characters

Text Content:
----------------------------------------------------------------------------------------------------
07] Jensen Huang: We're in a whole in the world. And it's only since 2016. And so eight years later, we've in increased the energy efficiency of computing by 10,000 times. And imagine if we became 10,000 times more energy efficient, or if a car was 10,000 times more energy efficient, or electric light bulb was 10,000 times more energy efficient. Our light bulb would be right now instead of 100 watts, 10,000 times less, producing the same illumination. Yeah. And so, and so the the energy efficiency of computing, particularly for AI computing that we've been working on, has advanced incredibly, and that's that's essential because we want to create, you know, more intelligent systems, and and we want to use um more computation to be smarter. And and uh so energy efficiency to do the work is our number one priority.
----------------------------------------------------------------------------------------------------


[CHUNK #100]
Chunk ID: data006_conv_56
Meeting ID: data006
Level: conversation
Text Length: 1374 characters

Text Content:
----------------------------------------------------------------------------------------------------
03] Cleo Abram: When I was preparing for this interview, I spoke to a lot of my engineering friends, and this is a question that they really wanted me to ask. So you're really speaking to your people here. You've shown a value um of increasing accessibility and abstraction with Cuda and allowing more people to use more computing power in all kinds of other ways. As applications of technology get more specific, I'm thinking of Transformers in AI, for example. For the audience, a Transformer is a very popular, more recent structure of AI that's now used in a huge number of the tools that you've seen. The reason that they're popular is because Transformers are structured in a way that helps them pay attention to key bits of information and give much better results. You could build chips that are perfectly suited for just one kind of AI model, but if you do that, then you're making them less able to do other things. So as these specific structures or architectures of AI get more popular, my understanding is there's a debate between how much you place these bets on burning them into the chip or designing hardware that is very specific to a certain task versus staying more general. And so my question is, how do you make those bets? How do you think about whether the solution is a car that could go anywhere or it's really optimizing a train to go from A to B?
----------------------------------------------------------------------------------------------------


[CHUNK #101]
Chunk ID: data006_conv_57
Meeting ID: data006
Level: conversation
Text Length: 100 characters

Text Content:
----------------------------------------------------------------------------------------------------
27] Cleo Abram: You're making bets with huge stakes, and I'm curious how you think about that. Yeah.
----------------------------------------------------------------------------------------------------


[CHUNK #102]
Chunk ID: data006_conv_58
Meeting ID: data006
Level: conversation
Text Length: 2594 characters

Text Content:
----------------------------------------------------------------------------------------------------
31] Jensen Huang: And and that that now comes back to um uh exactly your question: what are your core beliefs? And and the question, the the core belief, either one, that Transformer is the last AI algorithm, AI architecture that any researcher will ever discover again, or that um Transformer is a stepping stone towards uh evolutions of Transformers that are uh barely recognizable as a Transformer uh years from now. And we believe the latter. And the reason for that is because um you just have to go back in history and ask yourself, in the world of of uh computer algorithms, in the world of software, in the world of of um uh uh engineering and innovation, has one idea stayed along that long? And the answer is no. And so that's the, that's kind of the beau that's, that's in fact the essential beauty of a computer, that it's able to do something today that no one even imagined possible 10 years ago. And if you would have if you would have turned that computer 10 years ago into a microwave, then why would the applications keep coming? And so we believe, we believe in the in the in the richness of innovation and the richness of invention, and we want to create an architecture that let inventors and innovators and software programmers and AI researchers swim in the soup and come up with some amazing ideas. Look at Transformers. The the fundamental characteristic of a Transformer is this idea called attention mechanism, and it basically says the Transformer is going to understand the meaning and the relevance of every single word with every other word. So if you had 10 words, it has to figure out the relationship across 10 of them. But if you have a 100,000 words, or if you're context is now as large as read a PDF and that read a whole bunch of PDFs and the context window is now like a million tokens, the processing all of it across all of it is just impossible. And so the way you solve that problem is there all kinds of new ideas: flash attention or hierarchical attention or, you know, all the wave attention I just writ read about the other day. Um, the number of different types of attention mechanisms that have been invented since the Transformer is quite extraordinary. And so, so I I think that that's going to continue, and um, we believe it's going to continue, and that that computer science hasn't ended and that AI research have not all given up, and we haven't given up anyhow. And and uh, and that that having a computer that enables the the the flexibility of of research and innovation and and um new ideas is fundamentally the most important thing.
----------------------------------------------------------------------------------------------------


[CHUNK #103]
Chunk ID: data006_conv_59
Meeting ID: data006
Level: conversation
Text Length: 441 characters

Text Content:
----------------------------------------------------------------------------------------------------
29] Cleo Abram: One of the things that I am just so curious about, you design the chips, there are companies that assemble the chips, there are companies that design hardware to make it possible to work at nanometer scale. When you're designing tools like this, how do you think about design in the context of what's physically possible right now to make? What are the things that you're thinking about with sort of pushing that limit today?
----------------------------------------------------------------------------------------------------


[CHUNK #104]
Chunk ID: data006_conv_60
Meeting ID: data006
Level: conversation
Text Length: 1253 characters

Text Content:
----------------------------------------------------------------------------------------------------
58] Jensen Huang: Um, the way we do it is even though, even though we have things made, like for example, our chips are made by TSMC, um, even though we have them made by TSMC, we assume that we need to have the deep expertise that TSMC has. And so we have people in our company who are incredibly good at semiconductive physics so that we have a feeling for, we have an intuition for what are the limits of of of what today's semiconductor physics can do, and then we work very closely with them to discover the limits because we're trying to push the limits. And so we discover the limits together. Now we do the same thing in system engineering and cooling systems. It turns out plumbing is really important to us because of liquid cooling, and maybe fans are really important to us because of air cooling. And we're trying to design these fans in a way almost like, you know, they're aerodynamically sound so that we could pass the highest volume of air, make the least amount of noise. So we have aerodynamics engineers in our in our company. And so even though, even though we don't make them, uh we design them, and we have to ex deep expertise of knowing how to have them made. And and um, and and from that, we we uh, we try to push the limits.
----------------------------------------------------------------------------------------------------


[CHUNK #105]
Chunk ID: data006_conv_61
Meeting ID: data006
Level: conversation
Text Length: 325 characters

Text Content:
----------------------------------------------------------------------------------------------------
13] Cleo Abram: One of the themes of this conversation is that you are a person who makes big bets on the future, and time and time again you've been right about those bets. We've talked about GPUs, we've talked about Cuda, we've talked about bets you've made in AI self-driving cars, and we're going to be right on robotics.
----------------------------------------------------------------------------------------------------


[CHUNK #106]
Chunk ID: data006_conv_62
Meeting ID: data006
Level: conversation
Text Length: 2264 characters

Text Content:
----------------------------------------------------------------------------------------------------
36] Jensen Huang: We're going to be right. The latest bet, of course, we just described at the CES, and I'm very, very proud of it and and I'm very excited about it is the fusion of Omniverse and Cosmos so that we have this new type of generative world generation system, this Multiverse generation system. I, I think that's going to be profoundly important in the future of of uh robotics and physical systems. Of course, the work that we're doing with human robots, developing the tooling systems and the training systems and um the human demonstration systems and all all of this stuff that that you've already mentioned, we're, we're just seeing the beginnings of of that work, and uh I think the next five years are going to be very interesting in the world of human robotics. Of course, the work that we're doing in um digital biology so that we can understand the language of molecules and understand the language of cells, and just as we understand the language of physics and the physical world, we'd like to understand the language of the human body and understand the language of biology. And so if we can learn that uh and we can predict it, then all of a sudden uh our ability to have a digital twin of the human is plausible. And so I'm very excited about that work. I love the work that we're doing in uh climate science and be able to from weather predictions understand and predict the high resolution regional climates, the weather patterns uh within a kilometer above your head um, that we can somehow predict that with great accuracy, uh its implications is really quite profound. Uh, and so the number of things that we're working on is is really cool. You know, we we're, we're fortunate that uh we've created this this instrument that that is a a time machine, and we need time machines in all of these areas that we just talked about so that so that we can see the future. And if we could see the future and we can predict the future, then we have a better chance of making that future the best version of it. And and that's the reason why scientists want to predict the future. That's the reason why that's the reason why we try to predict the future and everything that we try to design so that we we can um optimize for the best version.
----------------------------------------------------------------------------------------------------


[CHUNK #107]
Chunk ID: data006_conv_63
Meeting ID: data006
Level: conversation
Text Length: 694 characters

Text Content:
----------------------------------------------------------------------------------------------------
04] Cleo Abram: So if someone is watching this and maybe they came into this video knowing that Nvidia is an incredibly important company but not fully understanding why or how it might affect their life, and they're now hopefully better understanding a big shift that we've gone through over the last few decades in computing, this very exciting, very sort of strange moment that we're in right now where we're sort of on the precipice of so many different things, if they would like to be able to look into the future a little bit, how would you advise them to prepare or to think about this moment that they're in personally with respect to how these tools are actually going to affect them?
----------------------------------------------------------------------------------------------------


[CHUNK #108]
Chunk ID: data006_conv_64
Meeting ID: data006
Level: conversation
Text Length: 3927 characters

Text Content:
----------------------------------------------------------------------------------------------------
47] Jensen Huang: Well, there are several ways to reason about about the future that we're creating. Um, uh, one way to reason about it is, suppose the work that you do uh continues to be important, but but the effort by which you do it um went from, you know, being a week long to almost instantaneous, you know, that that the effort of drudgery uh basically goes to zero. What is the implication of that? Uh, this is this is very similar to what would change if all of a sudden we had highways in this country. And that kind of happened, you know, in the last Industrial Revolution. All of a sudden we have interstate highways. And when you have interstate highways, what happens? Well, you know, suburbs start to be created, and and all of a sudden um, you know, distribution of goods from east to west is is is no longer a concern, and um, all of a sudden gas stations start cropping up on highways and uh, and uh um fast food restaurants show up and, you know, some some motels show up because people, you know, traveling across the state across the country and just wanted to stay somewhere for a few hours or overnight. And and so all of a sudden new economies and new capabilities, new economies. Um, what would happen if if a video conference made it possible for us to see each other uh without having to travel anymore? That all of a sudden it's actually okay to work far further away from home and uh from from uh from work, work and live further away. Uh, and so, so you ask yourself kind of these these questions, you know, what would happen if if um uh I have a software programmer with me all the time, and whatever it is I I can dream up, the software programmer could write for me, you know. What what would that do? Uh, what would happen if if um uh if I just had a seed of an idea and and I rough it out, and all of a sudden a, you know, a prototype of a a production was put in front of me? And what how would that change my life and how would that change my opportunity? And um, you know, what what does it free me to be able to do and and so on and so forth? And so, so I think that the next the next decade intelligence, um, not for everything, uh but for for some things, would basically become superhuman. And and so, so um, uh, but I can tell you exactly what that feels like. I'm surrounded by superhuman people, super intelligence from my perspective, because they're the best in the world at what they do, and they do what they do way better than I can do it. And and I'm surrounded by thousands of them. And yet, what it it never one day um caused me to to think all of a sudden I'm no longer necessary. It actually empowers me and gives me the confidence to go tackle more and more ambitious things. And so, so suppose suppose now everybody is surrounded by these super AIs that are very good at specific things or good at some of the things, what would that make you feel? Well, it's going to empower you. It's going to make you feel confident. Uh, and and I I'm pretty sure you probably use Chat GPT and AI. And um, I feel I feel more empowered today, more confident to learn something today. The knowledge of almost any particular field, the barriers to that understanding it has been reduced, and I have a personal tutor with me all of the time. And and so I I think that that feeling should be universal, and and I if if there's one thing that I would encourage everybody to do is to go get yourself an AI tutor right away. And that AI tutor could of course just teach your things uh anything you like, um, uh help you program, uh help you write, uh help you analyze, help you think, help you reason, uh, you know, all of those things uh is going to really make you feel empowered. And and um, I think that that's that's going to be our future. We're going to become we're going to become super humans, not because we have super we're going to become super humans because we have super AIs.
----------------------------------------------------------------------------------------------------


[CHUNK #109]
Chunk ID: data006_conv_65
Meeting ID: data006
Level: conversation
Text Length: 75 characters

Text Content:
----------------------------------------------------------------------------------------------------
23] Cleo Abram: Could you tell us a little bit about each of these objects?
----------------------------------------------------------------------------------------------------


[CHUNK #110]
Chunk ID: data006_conv_66
Meeting ID: data006
Level: conversation
Text Length: 1085 characters

Text Content:
----------------------------------------------------------------------------------------------------
28] Jensen Huang: This is a new GeForce graphics card, and yes, and uh this is the RTX 50 Series. It is essentially a supercomputer that you put into your PC, and we use it for gaming. Of course, people today use it for design and creative arts, and it does amazing AI. And the the real breakthrough here, and this is this is truly an amazing amazing thing, GeForce enabled AI, and it enabled Jeff Hinton, Alias, and Alex Krizhevsky to be able to train AlexNet. We discovered AI and we advanced AI, then AI came back to GeForce to help computer graphics. And so here's the amazing thing: out of 8 million pixels or so in a 4K display, we are computing, we're processing only 500,000 of them. The rest of them, we use AI to predict. The AI guessed it, and yet the image is perfect. We inform it by the 500,000 pixels that we computed, and we ray traced every single one, and it's all beautiful, it's perfect. And then we tell the AI, if these are the 500,000 perfect pixels in this screen, what are the other 8 million? And it goes, it fills in the rest of the screen, and it's perfect.
----------------------------------------------------------------------------------------------------


[CHUNK #111]
Chunk ID: data006_conv_67
Meeting ID: data006
Level: conversation
Text Length: 200 characters

Text Content:
----------------------------------------------------------------------------------------------------
48] Cleo Abram: And if you only have to do fewer pixels, are you able to invest more in doing that because you have fewer to do, so then the quality is better? So the extrapolation that the AI does...
----------------------------------------------------------------------------------------------------


[CHUNK #112]
Chunk ID: data006_conv_68
Meeting ID: data006
Level: conversation
Text Length: 1466 characters

Text Content:
----------------------------------------------------------------------------------------------------
59] Jensen Huang: Exactly. Because whatever computing, whatever attention you have, whatever resources you have, you can place it into 500,000 pixels. Now, this is a perfect example of why AI is going to make us all superhuman because all of the other things that it can do, it'll do for us, allows us to take our time and energy and focus it on the really, really valuable things that we do. And so we'll take our own resource, which is, you know, energy intensive, attention intensive, and we'll dedicate it to the few 100,000 pixels and use AI to super reses it, upres it, you know, to everything else. And so this this graphics card is now powered mostly by AI, and uh the computer graphics technology inside is incredible as well. And then this next one, uh as I mentioned earlier, in 2016 I built the first one for uh AI researchers, and we delivered the first one to Open AI, and Elon was there to receive it. And this this version, um, uh, I built a mini mini version, and the reason for that is because AI has now gone from AI researchers to every engineer, every student, every AI scientist, and and AI is going to be everywhere. And so instead of these $250,000 versions, we're going to make these $3,000 versions, and schools can have them, you know, students can have them. And you set it next to your PC or Mac, and um all of a sudden you have your own AI supercomputer, and you could you develop and build AIs, build your own AI, build your own R2-D2.
----------------------------------------------------------------------------------------------------


[CHUNK #113]
Chunk ID: data006_conv_69
Meeting ID: data006
Level: conversation
Text Length: 98 characters

Text Content:
----------------------------------------------------------------------------------------------------
42] Cleo Abram: What do you feel like is important for this audience to know that I haven't asked?
----------------------------------------------------------------------------------------------------


[CHUNK #114]
Chunk ID: data006_conv_70
Meeting ID: data006
Level: conversation
Text Length: 2026 characters

Text Content:
----------------------------------------------------------------------------------------------------
46] Jensen Huang: One of the most important things I would advise is, for example, if I were a student today, the first thing I would do is to learn AI. How do I learn to interact with Chat GPT? How do I learn to interact with Gemini Pro? And how do I learn to interact with Grok? And and um I, these learning how to interact with with AI is not unlike being someone who is really good at asking questions. You're incredibly good at asking questions, and and prompting AI is very, very similar. You, you, you, you can't just randomly ask a bunch of questions. And and so asking asking an AI to be assistant to you requires requires some expertise in in artistry and how to prompt it. And so if I were if I were a student today, irrespective whether it's for uh for math or for science or chemistry or biology or doesn't matter what field of science I'm going to go into or what profession I am, I'm going to ask myself, how can I use AI to do my job better? If I want to be a a lawyer, how can I use AI to be a better lawyer? If I want to be a better do doctor, how can I use AI to be a better doctor? If I want to be a chemist, how do I use AI to be a better chemist? If I want to be a biologist, I how do I use AI to be a better biologist? That question should be persistent across everybody. And just as my generation um grew up as the first generation that has to ask ourselves, how can we use computers to do our jobs better? Yeah. The generation before us had no computers. My generation was the first generation that had to ask the question, how do I use computers to do my job better? Remember I came into the industry before Windows 95, right? 1984, there were no computers in offices. And after that, shortly after that, computers started to emerge. And so we had to ask ourselves, how do we use computers to do our jobs better? The next generation doesn't have to ask that question, but it has to ask, obviously, next question, how can I use AI to do my job better? That is start and finish, I think, for everybody.
----------------------------------------------------------------------------------------------------


[CHUNK #115]
Chunk ID: data006_conv_71
Meeting ID: data006
Level: conversation
Text Length: 106 characters

Text Content:
----------------------------------------------------------------------------------------------------
55] Cleo Abram: It's a really exciting and scary and therefore worthwhile question, I think, for everyone.
----------------------------------------------------------------------------------------------------


[CHUNK #116]
Chunk ID: data006_conv_72
Meeting ID: data006
Level: conversation
Text Length: 1109 characters

Text Content:
----------------------------------------------------------------------------------------------------
00] Cleo Abram: I think it's it's going to be incredibly fun. AI is obviously a word that people are just learning now, but it's just, you know, what would it is, it's made your computer so much more accessible. It is easier to prompt Chat GPT to ask it anything you like than to go do the research yourself. And so we've lowered a barrier of understanding, we've lowered a barrier of knowledge, we've lowered a barrier of intelligence. And and um, uh, everybody really had to just go try it. You know, the thing that's really, really crazy is if I put a computer in front of somebody, and they've never used a computer, there is no chance they're going to learn that computer in a day. There's just no chance. Somebody really has to show it to you. And uh yet with Chat GPT, if you don't know how to use it, all you have to do is type in, "I don't know how to use Chat GPT, tell me," and it would come back and give you some examples. And so that's the amazing thing. You know, this the the amazing thing about intelligence is uh it'll help you along the way and make you uh superum, you know, along the way.
----------------------------------------------------------------------------------------------------


[CHUNK #117]
Chunk ID: data006_conv_73
Meeting ID: data006
Level: conversation
Text Length: 392 characters

Text Content:
----------------------------------------------------------------------------------------------------
09] Cleo Abram: All right, I have one more question if you have a second. This is not something that I plan to ask you, but on the way here, uh, I'm a little bit afraid of planes, which is not my most reasonable quality. And the flight here was a little bit bumpy, very bumpy. And I'm sitting there and it's moving, and I'm thinking about what they're going to say at my funeral, and after...
----------------------------------------------------------------------------------------------------


[CHUNK #118]
Chunk ID: data006_conv_74
Meeting ID: data006
Level: conversation
Text Length: 43 characters

Text Content:
----------------------------------------------------------------------------------------------------
36] Jensen Huang: She asked good questions.
----------------------------------------------------------------------------------------------------


[CHUNK #119]
Chunk ID: data006_conv_75
Meeting ID: data006
Level: conversation
Text Length: 509 characters

Text Content:
----------------------------------------------------------------------------------------------------
39] Cleo Abram: That's that's that's what the tombstone's going to say. I hope so. Yeah. And after I loved my husband and my friends and my family, the thing that I hoped that they would talk about was optimism. I hope that they would recognize what I'm trying to do here. And I'm very curious for you, you've you've been doing this a long time. It feels like there's so much that you've described in this vision ahead. What would the theme be that you would want people to say about what you're trying to do?
----------------------------------------------------------------------------------------------------


[CHUNK #120]
Chunk ID: data006_conv_76
Meeting ID: data006
Level: conversation
Text Length: 2038 characters

Text Content:
----------------------------------------------------------------------------------------------------
00:15] Jensen Huang: Very simply, they made an extraordinary impact. And I think that we're fortunate because of some core beliefs a long time ago and sticking with those core beliefs, and um uh, building upon them, uh, we, we found ourselves today uh being one of the most, one of the many most important uh and consequential uh technology companies uh in the world, and potentially ever. And and and so we, we take we take that responsibility very seriously. Um, we work hard to make sure that the capabilities that we've created are available to uh large companies as well as individual researchers and developers uh across every field of science, no matter profitable or not, uh big or small, famous or otherwise. Um, and and it's because of this this understanding of the consequential work that we're doing and the potential impact it has on so many people, uh that we want to make make this capability uh as as uh as pervasively as possible. And um I do think that that when we look back in a few years, uh and I do hope that what what uh the next generation realized uh is, as they they, well, first of all, they're going to know us because of all the, you know, gaming technology we create. I I do think that we'll look back and the whole field of digital biology and life sciences has been transformed. Our whole understanding of of um material sciences uh has complet been revolutionized, uh that robots are helping us do dangerous and mundane things all over the place, uh that if we wanted to drive we can drive, but otherwise, you know, take a nap or um enjoy your car like it's a home theater of yours, uh, you know, read from work to home. And and at that point, you're hoping that you're you live far away, and so you could be in a car for longer. And, you know, and and and you look back and you realize that there's this company almost at the epicenter of all of that, and and uh happens to be the company that you grew up playing games with. And I I hope, I hope that that to be uh what what the next generation learn.
----------------------------------------------------------------------------------------------------


[CHUNK #121]
Chunk ID: data006_conv_77
Meeting ID: data006
Level: conversation
Text Length: 65 characters

Text Content:
----------------------------------------------------------------------------------------------------
02:49] Cleo Abram: Thank you so much for your time. I enjoyed it.
----------------------------------------------------------------------------------------------------


[CHUNK #122]
Chunk ID: data006_conv_78
Meeting ID: data006
Level: conversation
Text Length: 41 characters

Text Content:
----------------------------------------------------------------------------------------------------
02:51] Jensen Huang: Thank you. I'm glad.
----------------------------------------------------------------------------------------------------



━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

>>> MEETING: data007 <<<
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

[CHUNK #123]
Chunk ID: data007_conv_0
Meeting ID: data007
Level: conversation
Text Length: 1062 characters

Text Content:
----------------------------------------------------------------------------------------------------
# data007
00](http://www.youtube.com/watch?v=7zC8-06198g&t=0)] **Chris Anderson**: It's very nice to have you here. Let's see. First of all, you know, congratulations. You really pulled off something [[00:06](http://www.youtube.com/watch?v=7zC8-06198g&t=6)] remarkable on that grilling. You achieved something that very few people do, which was you pulled off a kind [[00:12](http://www.youtube.com/watch?v=7zC8-06198g&t=12)] of a bipartisan consensus in U.S. politics. That was great. You know, the bad news was that that consensus largely seemed [[00:21](http://www.youtube.com/watch?v=7zC8-06198g&t=21)] to be "we must ban TikTok." So, we're going to come to that in a bit, and I'm curious [[00:26](http://www.youtube.com/watch?v=7zC8-06198g&t=26)] about... but before we before we go there, we need to know about you. You seem to me [[00:32](http://www.youtube.com/watch?v=7zC8-06198g&t=32)] like a remarkable person. I want to know a bit of your story and how you came to TikTok [[00:36](http://www.youtube.com/watch?v=7zC8-06198g&t=36)] in the first place.
----------------------------------------------------------------------------------------------------


[CHUNK #124]
Chunk ID: data007_conv_1
Meeting ID: data007
Level: conversation
Text Length: 778 characters

Text Content:
----------------------------------------------------------------------------------------------------
36](http://www.youtube.com/watch?v=7zC8-06198g&t=36)] **Shou Chew**: Okay, thank you, Chris. Before we do that, can I just check, I need [[00:41](http://www.youtube.com/watch?v=7zC8-06198g&t=41)] to know my audience. How many of you here use TikTok? Just... oh, thank you. For those who don't, [[00:46](http://www.youtube.com/watch?v=7zC8-06198g&t=46)] the Wi-Fi is free. So, that's another question, which is, how many of you here have had your lives touched [[00:55](http://www.youtube.com/watch?v=7zC8-06198g&t=55)] through TikTok, through your kids and other people in your lives? I mean, it's... oh, that's great to see. [[01:01](http://www.youtube.com/watch?v=7zC8-06198g&t=61)] It's basically, if you're alive, you have had some kind of contact with TikTok at this point.
----------------------------------------------------------------------------------------------------


[CHUNK #125]
Chunk ID: data007_conv_2
Meeting ID: data007
Level: conversation
Text Length: 103 characters

Text Content:
----------------------------------------------------------------------------------------------------
06](http://www.youtube.com/watch?v=7zC8-06198g&t=66)] **Chris Anderson**: Thank you. Tell us about you.
----------------------------------------------------------------------------------------------------


[CHUNK #126]
Chunk ID: data007_conv_3
Meeting ID: data007
Level: conversation
Text Length: 1580 characters

Text Content:
----------------------------------------------------------------------------------------------------
07](http://www.youtube.com/watch?v=7zC8-06198g&t=67)] **Shou Chew**: So, my name is Shou, and I'm from Singapore. Roughly 10 years ago, I [[01:13](http://www.youtube.com/watch?v=7zC8-06198g&t=73)] met with two engineers who were building a product, and the idea behind this was to build a product that [[01:21](http://www.youtube.com/watch?v=7zC8-06198g&t=81)] recommended content to people not based on who they knew, which was—if you think about it 10 years [[01:26](http://www.youtube.com/watch?v=7zC8-06198g&t=86)] ago, it was all the social graph was all in the rage, and the idea was, you know, your content [[01:33](http://www.youtube.com/watch?v=7zC8-06198g&t=93)] and the feed that you saw should be based on people that you knew. You know, about 10 years ago, [[01:37](http://www.youtube.com/watch?v=7zC8-06198g&t=97)] these two engineers thought about something different, which is, instead of showing you what you knew, instead of [[01:45](http://www.youtube.com/watch?v=7zC8-06198g&t=105)] showing you people you knew, why don't we show you content that you liked? And that's sort of the genesis [[01:50](http://www.youtube.com/watch?v=7zC8-06198g&t=110)] and the birth of the early iterations of TikTok. And about five years ago with the [[01:56](http://www.youtube.com/watch?v=7zC8-06198g&t=116)] advent of, you know, 4G, short video, mobile phone penetration, TikTok was born. And a couple of years [[02:04](http://www.youtube.com/watch?v=7zC8-06198g&t=124)] ago, you know, I had the opportunity to run this company, and it still excites me every single day. So...
----------------------------------------------------------------------------------------------------


[CHUNK #127]
Chunk ID: data007_conv_4
Meeting ID: data007
Level: conversation
Text Length: 1086 characters

Text Content:
----------------------------------------------------------------------------------------------------
10](http://www.youtube.com/watch?v=7zC8-06198g&t=130)] **Chris Anderson**: I want to dig in a little more into this about what was it that made this takeoff so explicit, [[02:15](http://www.youtube.com/watch?v=7zC8-06198g&t=135)] because the language I hear from people who spend time on it, it's sort of like— [[02:20](http://www.youtube.com/watch?v=7zC8-06198g&t=140)] I mean, it is a different level of addiction to other media out there, and I don't necessarily mean [[02:28](http://www.youtube.com/watch?v=7zC8-06198g&t=148)] this in a good way. We'll be coming on to it. There's good and bad things about this type of [[02:32](http://www.youtube.com/watch?v=7zC8-06198g&t=152)] addiction. But it's the feeling that within a couple days of experience of TikTok, it knows you [[02:38](http://www.youtube.com/watch?v=7zC8-06198g&t=158)] and it surprises you with things that you didn't know you were going to be interested in, but [[02:42](http://www.youtube.com/watch?v=7zC8-06198g&t=162)] you are. How is it really just instead of the social graph? What are these algorithms doing?
----------------------------------------------------------------------------------------------------


[CHUNK #128]
Chunk ID: data007_conv_5
Meeting ID: data007
Level: conversation
Text Length: 3674 characters

Text Content:
----------------------------------------------------------------------------------------------------
49](http://www.youtube.com/watch?v=7zC8-06198g&t=169)] **Shou Chew**: I think to describe this, to begin to answer your question, we have to talk about the mission of the company. [[02:56](http://www.youtube.com/watch?v=7zC8-06198g&t=176)] Now, the mission is to inspire creativity and to bring joy. And I think, you know, missions for companies like [[03:02](http://www.youtube.com/watch?v=7zC8-06198g&t=182)] ours is really important because you have product managers working on the product every single day, and they need to [[03:08](http://www.youtube.com/watch?v=7zC8-06198g&t=188)] have a North Star, you know, something to sort of work towards together. Now, based on this mission, our vision [[03:14](http://www.youtube.com/watch?v=7zC8-06198g&t=194)] is to provide three things to our users. We want to provide a window to discover, and I'll talk about [[03:20](http://www.youtube.com/watch?v=7zC8-06198g&t=200)] discovery you talked about this in a second. We want to give them a canvas to create, which is going [[03:25](http://www.youtube.com/watch?v=7zC8-06198g&t=205)] to be really exciting with new technologies in AI that's going to help people create new [[03:31](http://www.youtube.com/watch?v=7zC8-06198g&t=211)] things. And the final thing is bridges for people to connect. So that's sort of the vision of what we're [[03:37](http://www.youtube.com/watch?v=7zC8-06198g&t=217)] trying to build. Now, what really makes TikTok very unique and very different is the whole discovery engine behind [[03:45](http://www.youtube.com/watch?v=7zC8-06198g&t=225)] us. So, there are earlier apps that I have a lot of respect for, but they were built for a [[03:49](http://www.youtube.com/watch?v=7zC8-06198g&t=229)] different purpose. You know, for example, in the era of search, there was an app that was built [[03:55](http://www.youtube.com/watch?v=7zC8-06198g&t=235)] for people who wanted to search things, so that it's more easily found. And then in the era [[04:01](http://www.youtube.com/watch?v=7zC8-06198g&t=241)] of social graphs, it was about connecting people and their followers. Now, what we have done is that we are [[04:07](http://www.youtube.com/watch?v=7zC8-06198g&t=247)] based on our machine learning algorithms, we're showing people what they like. And what this means is that we have [[04:13](http://www.youtube.com/watch?v=7zC8-06198g&t=253)] given the everyday person a platform to be discovered. If you have talent, it is very, very easy to get [[04:19](http://www.youtube.com/watch?v=7zC8-06198g&t=259)] discovered on TikTok. And I'll just give you one example of this. The biggest creator on TikTok [[04:25](http://www.youtube.com/watch?v=7zC8-06198g&t=265)] is a guy called Khaby Lame. Khaby was from Senegal. He lives in Italy. He was a factory worker. [[04:33](http://www.youtube.com/watch?v=7zC8-06198g&t=273)] For the longest time didn't even speak in any of his videos, but what he did was, [[04:38](http://www.youtube.com/watch?v=7zC8-06198g&t=278)] he had talent, he was funny, he had a good expression, he had creativity, so he kept posting. And [[04:44](http://www.youtube.com/watch?v=7zC8-06198g&t=284)] today, he has 160 million followers on our platform. So, every single day we hear stories like that, you know, [[04:50](http://www.youtube.com/watch?v=7zC8-06198g&t=290)] businesses, people with talent. And I think it's very, it's very freeing to have a platform where as long as [[04:56](http://www.youtube.com/watch?v=7zC8-06198g&t=296)] you have talent, you're going to be heard, and you have the chance to succeed, and that's what we're providing [[05:01](http://www.youtube.com/watch?v=7zC8-06198g&t=301)] to our users.
----------------------------------------------------------------------------------------------------


[CHUNK #129]
Chunk ID: data007_conv_6
Meeting ID: data007
Level: conversation
Text Length: 1371 characters

Text Content:
----------------------------------------------------------------------------------------------------
01](http://www.youtube.com/watch?v=7zC8-06198g&t=301)] **Chris Anderson**: So, this is the amazing thing to me. We've, most of us have grown [[05:06](http://www.youtube.com/watch?v=7zC8-06198g&t=306)] up with say, network television, where for decades, you've had thousands of brilliant creative people toiling in the [[05:13](http://www.youtube.com/watch?v=7zC8-06198g&t=313)] trenches trying to imagine stuff that will be amazing for an audience, and none of them ever remotely came up [[05:22](http://www.youtube.com/watch?v=7zC8-06198g&t=322)] with anything that looked like many of your creators. So, these algorithms, by just by observing people's behavior [[05:32](http://www.youtube.com/watch?v=7zC8-06198g&t=332)] and what they look like, have discovered things that thousands of brilliant humans never discovered. Tell me some of the [[05:38](http://www.youtube.com/watch?v=7zC8-06198g&t=338)] things that it is looking at. So, obvious things like if someone presses like or stays on a video for [[05:44](http://www.youtube.com/watch?v=7zC8-06198g&t=344)] a long time, that gives you a clue, "more like that." But is it subject matter? What are [[05:49](http://www.youtube.com/watch?v=7zC8-06198g&t=349)] the array of things that you have noticed that you can actually track that provide useful [[05:54](http://www.youtube.com/watch?v=7zC8-06198g&t=354)] clues?
----------------------------------------------------------------------------------------------------


[CHUNK #130]
Chunk ID: data007_conv_7
Meeting ID: data007
Level: conversation
Text Length: 1394 characters

Text Content:
----------------------------------------------------------------------------------------------------
54](http://www.youtube.com/watch?v=7zC8-06198g&t=354)] **Shou Chew**: The, I'm going to simplify this a lot, but the machine learning, the recommendation algorithm is really just math. [[06:01](http://www.youtube.com/watch?v=7zC8-06198g&t=361)] So, for example, if you, if you like videos one, two, three, and four, and I like videos one, two, [[06:08](http://www.youtube.com/watch?v=7zC8-06198g&t=368)] three, and five, maybe he liked videos one, two, three, and six. Now, what's going to happen is because we [[06:13](http://www.youtube.com/watch?v=7zC8-06198g&t=373)] like one, two, three at the same time, he's going to be shown four, five, six, and so are we. [[06:17](http://www.youtube.com/watch?v=7zC8-06198g&t=377)] And you can think about this repeated at scale in real time across more than a billion people. That's basically [[06:24](http://www.youtube.com/watch?v=7zC8-06198g&t=384)] what it is. It's math. And of course, AI and machine learning has allowed this to be [[06:29](http://www.youtube.com/watch?v=7zC8-06198g&t=389)] done at a very, very big scale. And what we have seen the result of this is that they learned [[06:34](http://www.youtube.com/watch?v=7zC8-06198g&t=394)] the interest signals that people exhibit very quickly and shows you content that's really relevant for you in a very, [[06:41](http://www.youtube.com/watch?v=7zC8-06198g&t=401)] in a very quick way.
----------------------------------------------------------------------------------------------------


[CHUNK #131]
Chunk ID: data007_conv_8
Meeting ID: data007
Level: conversation
Text Length: 792 characters

Text Content:
----------------------------------------------------------------------------------------------------
41](http://www.youtube.com/watch?v=7zC8-06198g&t=401)] **Chris Anderson**: So, it's a form of collaborative filtering from what you're saying. That the theory [[06:48](http://www.youtube.com/watch?v=7zC8-06198g&t=408)] behind it is that these humans are weird people. We don't really know what they're interested in, but if [[06:52](http://www.youtube.com/watch?v=7zC8-06198g&t=412)] we see that one human is interested with an overlap of someone else, chances are, you know, you can [[06:58](http://www.youtube.com/watch?v=7zC8-06198g&t=418)] you can make use of the other pieces that are in that overlapped human's repertoire to feed [[07:05](http://www.youtube.com/watch?v=7zC8-06198g&t=425)] them, and they'll be surprised, but the reason they like it is because their peer also liked it.
----------------------------------------------------------------------------------------------------


[CHUNK #132]
Chunk ID: data007_conv_9
Meeting ID: data007
Level: conversation
Text Length: 1048 characters

Text Content:
----------------------------------------------------------------------------------------------------
09](http://www.youtube.com/watch?v=7zC8-06198g&t=429)] **Shou Chew**: It is [[07:10](http://www.youtube.com/watch?v=7zC8-06198g&t=430)] pattern recognition based on your interest signals. And I think the other thing here is that we don't actually ask [[07:16](http://www.youtube.com/watch?v=7zC8-06198g&t=436)] you 20 questions on whether you like a piece of content, you know, "what are your interests?" We don't do [[07:20](http://www.youtube.com/watch?v=7zC8-06198g&t=440)] that. We build that experience organically into the app experience. So, you are voting with your thumbs. You know, by [[07:27](http://www.youtube.com/watch?v=7zC8-06198g&t=447)] watching a video, by swiping it, by liking it, by sharing it, you are basically exhibiting interest signals. [[07:34](http://www.youtube.com/watch?v=7zC8-06198g&t=454)] And what it does mathematically is to take those signals, put it in a formula, and then matches it through [[07:39](http://www.youtube.com/watch?v=7zC8-06198g&t=459)] pattern recognition. That's basically the idea behind it.
----------------------------------------------------------------------------------------------------


[CHUNK #133]
Chunk ID: data007_conv_10
Meeting ID: data007
Level: conversation
Text Length: 589 characters

Text Content:
----------------------------------------------------------------------------------------------------
40](http://www.youtube.com/watch?v=7zC8-06198g&t=460)] **Chris Anderson**: I mean, lots of startups have tried to use these types [[07:48](http://www.youtube.com/watch?v=7zC8-06198g&t=468)] of techniques. I'm wondering what else played a role early on? I mean, how big a deal was it that [[07:52](http://www.youtube.com/watch?v=7zC8-06198g&t=472)] from the get-go you were optimizing for smartphones so that videos were shot in portrait format, and they [[07:59](http://www.youtube.com/watch?v=7zC8-06198g&t=479)] were short? Was that, was that an early distinguishing thing that mattered?
----------------------------------------------------------------------------------------------------


[CHUNK #134]
Chunk ID: data007_conv_11
Meeting ID: data007
Level: conversation
Text Length: 2675 characters

Text Content:
----------------------------------------------------------------------------------------------------
04](http://www.youtube.com/watch?v=7zC8-06198g&t=484)] **Shou Chew**: I think we were the first to really [[08:05](http://www.youtube.com/watch?v=7zC8-06198g&t=485)] try this at scale. The recommendation algorithm is a very important reason as to why the [[08:12](http://www.youtube.com/watch?v=7zC8-06198g&t=492)] platform is so popular among so many people, but beyond that, you know, you mentioned the format itself. So, [[08:20](http://www.youtube.com/watch?v=7zC8-06198g&t=500)] we talked about the vision of the company, which is to have a window to discover, and if you sort [[08:25](http://www.youtube.com/watch?v=7zC8-06198g&t=505)] of just open that for the first time, you see that it takes up your whole screen. So that's the [[08:28](http://www.youtube.com/watch?v=7zC8-06198g&t=508)] window that we want. You can imagine a lot of people using that window to discover new things in their [[08:33](http://www.youtube.com/watch?v=7zC8-06198g&t=513)] lives. Then, you know, through this recommendation algorithm, we have found that it connects people together, people find communities. And [[08:41](http://www.youtube.com/watch?v=7zC8-06198g&t=521)] I've heard so many stories of people who have found their communities because of the content that they're posting. Now, [[08:47](http://www.youtube.com/watch?v=7zC8-06198g&t=527)] I'll give you an example. I was in D.C. recently, and I met with a bunch of creators. [[08:53](http://www.youtube.com/watch?v=7zC8-06198g&t=533)] So, one of them was sitting next to me at the dinner. His name is Samuel. He [[09:00](http://www.youtube.com/watch?v=7zC8-06198g&t=540)] runs a restaurant in Phoenix, Arizona, and it's a taco restaurant. He told me he has never done this before, [[09:06](http://www.youtube.com/watch?v=7zC8-06198g&t=546)] first venture. He started posting all this content on TikTok, and I saw his content. [[09:12](http://www.youtube.com/watch?v=7zC8-06198g&t=552)] It looks... I was hungry after looking at it. It's just great content. And he's generated so much [[09:17](http://www.youtube.com/watch?v=7zC8-06198g&t=557)] interest in his business. Last year, he made something like a million dollars in revenue just via TikTok. [[09:23](http://www.youtube.com/watch?v=7zC8-06198g&t=563)] One restaurant. And again and again, I hear these stories. By connecting people together, by giving people the [[09:30](http://www.youtube.com/watch?v=7zC8-06198g&t=570)] window to discover, we have given many small businesses and many people, your common person, a voice that they will [[09:37](http://www.youtube.com/watch?v=7zC8-06198g&t=577)] never otherwise have, and I think that's the power of the platform.
----------------------------------------------------------------------------------------------------


[CHUNK #135]
Chunk ID: data007_conv_12
Meeting ID: data007
Level: conversation
Text Length: 1175 characters

Text Content:
----------------------------------------------------------------------------------------------------
42](http://www.youtube.com/watch?v=7zC8-06198g&t=582)] **Chris Anderson**: So, you definitely have identified early just how [[09:44](http://www.youtube.com/watch?v=7zC8-06198g&t=584)] we're social creatures, we need affirmation. I've heard a story—and you can tell me whether true or [[09:50](http://www.youtube.com/watch?v=7zC8-06198g&t=590)] not—that one of the keys to your early lift-off was that you wanted to persuade creators who were trying [[09:56](http://www.youtube.com/watch?v=7zC8-06198g&t=596)] out TikTok that this was a platform where they would get response early on. When you're trying [[10:02](http://www.youtube.com/watch?v=7zC8-06198g&t=602)] to grow something, the numbers aren't there for response. So, you had the brilliant idea of goosing those numbers a [[10:09](http://www.youtube.com/watch?v=7zC8-06198g&t=609)] bit, basically finding ways to give people a bigger sense of like, more likes, more engagement than was [[10:14](http://www.youtube.com/watch?v=7zC8-06198g&t=614)] actually the case by using AI agents somehow in the process. Is that a brilliant idea, or is [[10:21](http://www.youtube.com/watch?v=7zC8-06198g&t=621)] that just a myth?
----------------------------------------------------------------------------------------------------


[CHUNK #136]
Chunk ID: data007_conv_13
Meeting ID: data007
Level: conversation
Text Length: 1585 characters

Text Content:
----------------------------------------------------------------------------------------------------
22](http://www.youtube.com/watch?v=7zC8-06198g&t=622)] **Shou Chew**: I would describe it in a different [[10:25](http://www.youtube.com/watch?v=7zC8-06198g&t=625)] way. So, there are other platforms that exist before TikTok, and if you think about those platforms, [[10:31](http://www.youtube.com/watch?v=7zC8-06198g&t=631)] you sort of have to be famous already in order to get followers because the way it's built is that [[10:37](http://www.youtube.com/watch?v=7zC8-06198g&t=637)] people come and follow people, and if you are not really famous, the chances that you get [[10:42](http://www.youtube.com/watch?v=7zC8-06198g&t=642)] discovered are very, very low. Now, what we have done, again, because of the difference in the way we're recommending [[10:49](http://www.youtube.com/watch?v=7zC8-06198g&t=649)] content, is that we've given anyone, any single person with enough talent, a stage to be able to be discovered. [[10:56](http://www.youtube.com/watch?v=7zC8-06198g&t=656)] And I think that actually is the single probably the most important thing contributing to the growth of the platform. [[11:02](http://www.youtube.com/watch?v=7zC8-06198g&t=662)] And again and again, you will hear stories from people who use the platform, who post regularly on it, that [[11:08](http://www.youtube.com/watch?v=7zC8-06198g&t=668)] if they have something they want to say, the platform gives them the chance and the stage to connect with [[11:13](http://www.youtube.com/watch?v=7zC8-06198g&t=673)] their audience in a way that I think no other product in the past has ever offered them.
----------------------------------------------------------------------------------------------------


[CHUNK #137]
Chunk ID: data007_conv_14
Meeting ID: data007
Level: conversation
Text Length: 1324 characters

Text Content:
----------------------------------------------------------------------------------------------------
17](http://www.youtube.com/watch?v=7zC8-06198g&t=677)] **Chris Anderson**: So, I'm [[11:19](http://www.youtube.com/watch?v=7zC8-06198g&t=679)] just trying to play back what you said there. You said you were describing a different way. [[11:23](http://www.youtube.com/watch?v=7zC8-06198g&t=683)] What I what I said is, is it then the case that like, to give someone a decent chance—someone [[11:29](http://www.youtube.com/watch?v=7zC8-06198g&t=689)] who's brilliant but doesn't come with any followers initially—that you, you've got some technique to identify talent, [[11:36](http://www.youtube.com/watch?v=7zC8-06198g&t=696)] and that you will almost encourage them, you will give them some kind of [[11:40](http://www.youtube.com/watch?v=7zC8-06198g&t=700)] artificially increase the number of followers or likes or whatever that they have so that others are encouraged [[11:46](http://www.youtube.com/watch?v=7zC8-06198g&t=706)] to go, "wow, there's something there," and so forth. Like, it's this idea of critical mass that kind of every [[11:50](http://www.youtube.com/watch?v=7zC8-06198g&t=710)] entrepreneur, every party planner kind of knows about of, "no, no, this is the hot place in town, everyone come," [[11:55](http://www.youtube.com/watch?v=7zC8-06198g&t=715)] and that is how you actually gain critical mass.
----------------------------------------------------------------------------------------------------


[CHUNK #138]
Chunk ID: data007_conv_15
Meeting ID: data007
Level: conversation
Text Length: 500 characters

Text Content:
----------------------------------------------------------------------------------------------------
57](http://www.youtube.com/watch?v=7zC8-06198g&t=717)] **Shou Chew**: We want to make sure that every person who posts [[12:02](http://www.youtube.com/watch?v=7zC8-06198g&t=722)] a video is given an equal chance to be able to have some audience to begin with, but this [[12:07](http://www.youtube.com/watch?v=7zC8-06198g&t=727)] idea that you are maybe alluding to that we can get people to like something, it doesn't really work like [[12:15](http://www.youtube.com/watch?v=7zC8-06198g&t=735)] that.
----------------------------------------------------------------------------------------------------


[CHUNK #139]
Chunk ID: data007_conv_16
Meeting ID: data007
Level: conversation
Text Length: 310 characters

Text Content:
----------------------------------------------------------------------------------------------------
15](http://www.youtube.com/watch?v=7zC8-06198g&t=735)] **Chris Anderson**: But can you get, could you get AI agents to like something? Could you see the network work with [[12:20](http://www.youtube.com/watch?v=7zC8-06198g&t=740)] extra AI agents that could kind of, you know, give someone early encouragement?
----------------------------------------------------------------------------------------------------


[CHUNK #140]
Chunk ID: data007_conv_17
Meeting ID: data007
Level: conversation
Text Length: 1315 characters

Text Content:
----------------------------------------------------------------------------------------------------
24](http://www.youtube.com/watch?v=7zC8-06198g&t=744)] **Shou Chew**: Ultimately, what the machine does is it [[12:27](http://www.youtube.com/watch?v=7zC8-06198g&t=747)] recognizes people's interests. So, if you post something that's not interesting to a lot of people, even if you gave [[12:32](http://www.youtube.com/watch?v=7zC8-06198g&t=752)] it a lot of exposure, you're not going to get the virality that you want. Whereas, so it's a lot [[12:38](http://www.youtube.com/watch?v=7zC8-06198g&t=758)] of, you know, there is no, there's no push here. It's not like you can go and [[12:42](http://www.youtube.com/watch?v=7zC8-06198g&t=762)] push something because I like Chris, I'm going to push your content, and it doesn't work like that. [[12:47](http://www.youtube.com/watch?v=7zC8-06198g&t=767)] You've got to have a message that resonates with people, and if it does, then it will automatically just have [[12:52](http://www.youtube.com/watch?v=7zC8-06198g&t=772)] the virality itself. That's the beauty of user-generated content. It's not something that can be engineered or over [[13:00](http://www.youtube.com/watch?v=7zC8-06198g&t=780)] thought. It really is something that has to resonate with the audience, and if it does, then it [[13:05](http://www.youtube.com/watch?v=7zC8-06198g&t=785)] goes viral.
----------------------------------------------------------------------------------------------------


[CHUNK #141]
Chunk ID: data007_conv_18
Meeting ID: data007
Level: conversation
Text Length: 613 characters

Text Content:
----------------------------------------------------------------------------------------------------
05](http://www.youtube.com/watch?v=7zC8-06198g&t=785)] **Chris Anderson**: I was speaking privately with an investor who knows your company quite well, who said [[13:11](http://www.youtube.com/watch?v=7zC8-06198g&t=791)] that actually the level of sophistication of the algorithms you have going is just another order of [[13:18](http://www.youtube.com/watch?v=7zC8-06198g&t=798)] magnitude to what competitors like Facebook or YouTube have going. Is that, is that just hype, or [[13:25](http://www.youtube.com/watch?v=7zC8-06198g&t=805)] do you, do you really believe you, like, how complex are these algorithms?
----------------------------------------------------------------------------------------------------


[CHUNK #142]
Chunk ID: data007_conv_19
Meeting ID: data007
Level: conversation
Text Length: 1711 characters

Text Content:
----------------------------------------------------------------------------------------------------
28](http://www.youtube.com/watch?v=7zC8-06198g&t=808)] **Shou Chew**: Well, I think in terms of complexity, [[13:33](http://www.youtube.com/watch?v=7zC8-06198g&t=813)] there are many companies with a lot of resources and a lot of talent, you know, they will figure out [[13:37](http://www.youtube.com/watch?v=7zC8-06198g&t=817)] the, even the most complex algorithms. I think what is very different is your mission of your company, [[13:43](http://www.youtube.com/watch?v=7zC8-06198g&t=823)] how you started the company. Like I said, we started with this idea that this was the main [[13:49](http://www.youtube.com/watch?v=7zC8-06198g&t=829)] use case, the most important use case, is you come and you get to see recommended content. Now, for some [[13:55](http://www.youtube.com/watch?v=7zC8-06198g&t=835)] other apps out there, they are very significant and have a lot of users, they're built for a different original [[14:00](http://www.youtube.com/watch?v=7zC8-06198g&t=840)] purpose. And if you're built for something different, then your users are used to that because the community comes in [[14:06](http://www.youtube.com/watch?v=7zC8-06198g&t=846)] and they expect that sort of experience. So, I think the pivot away from that, it's not, it's not really [[14:11](http://www.youtube.com/watch?v=7zC8-06198g&t=851)] just a matter of engineering and algorithms. It's a matter of what your company is built to begin with, which [[14:18](http://www.youtube.com/watch?v=7zC8-06198g&t=858)] is why I started this by saying you need to have a vision, you need to have a mission, and [[14:22](http://www.youtube.com/watch?v=7zC8-06198g&t=862)] that's the North Star where you can't just shift it halfway, right?
----------------------------------------------------------------------------------------------------


[CHUNK #143]
Chunk ID: data007_conv_20
Meeting ID: data007
Level: conversation
Text Length: 733 characters

Text Content:
----------------------------------------------------------------------------------------------------
25](http://www.youtube.com/watch?v=7zC8-06198g&t=865)] **Chris Anderson**: And is it fair to say that [[14:27](http://www.youtube.com/watch?v=7zC8-06198g&t=867)] because your start point has been interest algorithms rather than social graph algorithms, you've been able to avoid some of [[14:33](http://www.youtube.com/watch?v=7zC8-06198g&t=873)] the worst of the sort of the filter bubbles that have happened in other social media where you have tribes [[14:38](http://www.youtube.com/watch?v=7zC8-06198g&t=878)] kind of declaring war on each other effectively, and so much of the noise and energy is around [[14:44](http://www.youtube.com/watch?v=7zC8-06198g&t=884)] that? Do you believe that you've largely avoided that on TikTok?
----------------------------------------------------------------------------------------------------


[CHUNK #144]
Chunk ID: data007_conv_21
Meeting ID: data007
Level: conversation
Text Length: 1391 characters

Text Content:
----------------------------------------------------------------------------------------------------
46](http://www.youtube.com/watch?v=7zC8-06198g&t=886)] **Shou Chew**: The diversity of content that our users [[14:51](http://www.youtube.com/watch?v=7zC8-06198g&t=891)] see is very key, you know, in order for the discovery—and the mission is to discover, so, sorry, [[00:00](http://www.youtube.com/watch?v=7zC8-06198g&t=0)] the vision is to discover. So, in order to facilitate that, it is very important to us that what the [[15:03](http://www.youtube.com/watch?v=7zC8-06198g&t=903)] users see is the diversity of content. Now, generally speaking, you know, there are certain issues that you mentioned [[15:10](http://www.youtube.com/watch?v=7zC8-06198g&t=910)] that the industry faces. You know, there are some bad actors who come on the internet, they post bad content. [[15:15](http://www.youtube.com/watch?v=7zC8-06198g&t=915)] Our approach is that we have very clear Community Guidelines. We're very transparent about what is allowed and [[15:22](http://www.youtube.com/watch?v=7zC8-06198g&t=922)] what is not allowed on our platform. No executives make any ad hoc decisions. And based on that, we have [[15:28](http://www.youtube.com/watch?v=7zC8-06198g&t=928)] built a team that is tens of thousands of people plus machines in order to identify content that is bad [[15:35](http://www.youtube.com/watch?v=7zC8-06198g&t=935)] and actively and proactively remove it from the platform.
----------------------------------------------------------------------------------------------------


[CHUNK #145]
Chunk ID: data007_conv_22
Meeting ID: data007
Level: conversation
Text Length: 124 characters

Text Content:
----------------------------------------------------------------------------------------------------
38](http://www.youtube.com/watch?v=7zC8-06198g&t=938)] **Chris Anderson**: Talk about what some of those key guidelines are.
----------------------------------------------------------------------------------------------------


[CHUNK #146]
Chunk ID: data007_conv_23
Meeting ID: data007
Level: conversation
Text Length: 1354 characters

Text Content:
----------------------------------------------------------------------------------------------------
40](http://www.youtube.com/watch?v=7zC8-06198g&t=940)] **Shou Chew**: We have [[15:42](http://www.youtube.com/watch?v=7zC8-06198g&t=942)] it published on our website. We just, in March, we just iterated a new version to make it [[15:48](http://www.youtube.com/watch?v=7zC8-06198g&t=948)] more readable. So, there are many things, like, for example, no pornography, clearly no child sexual abuse material, and [[15:55](http://www.youtube.com/watch?v=7zC8-06198g&t=955)] other bad things, no violence, for example. We also make it clear that there's a differentiated experience if you're below [[16:02](http://www.youtube.com/watch?v=7zC8-06198g&t=962)] 18 years old. So, if you're below 18 years, for example, your entire app experience is actually more restricted. [[16:09](http://www.youtube.com/watch?v=7zC8-06198g&t=969)] We don't allow, as an example, users below 16 by default to go viral. We don't allow that. If you're [[16:17](http://www.youtube.com/watch?v=7zC8-06198g&t=977)] below 16, we don't allow you to use the instant messaging feature in-app. If you're below 18, we [[16:24](http://www.youtube.com/watch?v=7zC8-06198g&t=984)] don't allow you to use the live streaming features. And of course, we give parents a whole set of tools [[16:28](http://www.youtube.com/watch?v=7zC8-06198g&t=988)] to control their teenagers' experience as well.
----------------------------------------------------------------------------------------------------


[CHUNK #147]
Chunk ID: data007_conv_24
Meeting ID: data007
Level: conversation
Text Length: 128 characters

Text Content:
----------------------------------------------------------------------------------------------------
32](http://www.youtube.com/watch?v=7zC8-06198g&t=992)] **Chris Anderson**: But how do you how do you know the age of your users?
----------------------------------------------------------------------------------------------------


[CHUNK #148]
Chunk ID: data007_conv_25
Meeting ID: data007
Level: conversation
Text Length: 1627 characters

Text Content:
----------------------------------------------------------------------------------------------------
34](http://www.youtube.com/watch?v=7zC8-06198g&t=994)] **Shou Chew**: In our industry, we do. We rely mainly on something called age-gating, which is when you sign up for [[16:40](http://www.youtube.com/watch?v=7zC8-06198g&t=1000)] the app for the first time, and we ask you for the age. Now, beyond that, we also have [[16:46](http://www.youtube.com/watch?v=7zC8-06198g&t=1006)] we also have built tools to go through your public profile. For example, when you post a video, we try and [[16:51](http://www.youtube.com/watch?v=7zC8-06198g&t=1011)] match what the age that you said with the video that you just posted. Now, there are questions of, "can [[16:56](http://www.youtube.com/watch?v=7zC8-06198g&t=1016)] we do more?" And that question is always, for every company, by the way, in our industry, has to [[17:02](http://www.youtube.com/watch?v=7zC8-06198g&t=1022)] be balanced with privacy. Now, if, for example, you know, we scan the faces of every single user, [[17:09](http://www.youtube.com/watch?v=7zC8-06198g&t=1029)] then, you know, we will significantly increase the ability to tell their age, but we will also significantly increase [[17:15](http://www.youtube.com/watch?v=7zC8-06198g&t=1035)] the amount of data that we collect on you. Now, we don't want to collect data, we don't want to [[17:19](http://www.youtube.com/watch?v=7zC8-06198g&t=1039)] scan data on your face to collect that. So, that balance has to be maintained, and it's a challenge that [[17:24](http://www.youtube.com/watch?v=7zC8-06198g&t=1044)] we are working through together with, you know, industry, together with the regulators as well.
----------------------------------------------------------------------------------------------------


[CHUNK #149]
Chunk ID: data007_conv_26
Meeting ID: data007
Level: conversation
Text Length: 597 characters

Text Content:
----------------------------------------------------------------------------------------------------
28](http://www.youtube.com/watch?v=7zC8-06198g&t=1048)] **Chris Anderson**: So, look, one thing that [[17:31](http://www.youtube.com/watch?v=7zC8-06198g&t=1051)] is unquestionable is that you have created a platform for literally millions of people who never thought they were [[17:36](http://www.youtube.com/watch?v=7zC8-06198g&t=1056)] going to be a content creator, you've given them an audience. I'd actually like to hear from you one other [[17:42](http://www.youtube.com/watch?v=7zC8-06198g&t=1062)] favorite example of someone who TikTok has given an audience to that never had that before.
----------------------------------------------------------------------------------------------------


[CHUNK #150]
Chunk ID: data007_conv_27
Meeting ID: data007
Level: conversation
Text Length: 2264 characters

Text Content:
----------------------------------------------------------------------------------------------------
46](http://www.youtube.com/watch?v=7zC8-06198g&t=1066)] **Shou Chew**: I think, [[17:48](http://www.youtube.com/watch?v=7zC8-06198g&t=1068)] you know, so when, again, when I meet with, when I travel around the world, I meet with [[17:52](http://www.youtube.com/watch?v=7zC8-06198g&t=1072)] a whole bunch of creators on our platform. I was in South Korea just yesterday, and before that, [[17:59](http://www.youtube.com/watch?v=7zC8-06198g&t=1079)] I met with, before that, I met with a bunch of people. Don't expect, for example, teachers. There [[18:05](http://www.youtube.com/watch?v=7zC8-06198g&t=1085)] is an English teacher from Arkansas, her name is Claudine, and I met her in person. She uses her platform [[18:12](http://www.youtube.com/watch?v=7zC8-06198g&t=1092)] to reach out to students. You know, there is another teacher called Chemical Kin, and Chemical Kim teaches chemistry. [[18:20](http://www.youtube.com/watch?v=7zC8-06198g&t=1100)] What she does is she uses our platform to reach out to a much broader student base than she has in [[18:25](http://www.youtube.com/watch?v=7zC8-06198g&t=1105)] her classroom. And they're both very, very popular. In fact, what we have realized is that STEM content [[18:34](http://www.youtube.com/watch?v=7zC8-06198g&t=1114)] has over 116 billion views on our platform globally, and is so significant—a cumulative 160 billion is [[18:44](http://www.youtube.com/watch?v=7zC8-06198g&t=1124)] so significant—that in the U.S. we have started testing creating a feed just for STEM content, just for STEM [[18:51](http://www.youtube.com/watch?v=7zC8-06198g&t=1131)] content. I've been using it for a while and I learned something new. You want to know what it is? [[18:56](http://www.youtube.com/watch?v=7zC8-06198g&t=1136)] Apparently, if you flip an egg, you know, on your tray, the egg will last longer. It's science! There's a [[19:04](http://www.youtube.com/watch?v=7zC8-06198g&t=1144)] whole video on this. I learned this on TikTok. You can search for this. You want to [[19:07](http://www.youtube.com/watch?v=7zC8-06198g&t=1147)] know something else about an egg? If you put it in just one hand and squeeze it as hard as [[19:11](http://www.youtube.com/watch?v=7zC8-06198g&t=1151)] you can, it will never break.
----------------------------------------------------------------------------------------------------


[CHUNK #151]
Chunk ID: data007_conv_28
Meeting ID: data007
Level: conversation
Text Length: 1856 characters

Text Content:
----------------------------------------------------------------------------------------------------
12](http://www.youtube.com/watch?v=7zC8-06198g&t=1152)] **Chris Anderson**: Yes, I think I read about that too. It's not somewhere we can search [[19:19](http://www.youtube.com/watch?v=7zC8-06198g&t=1159)] for it. But look, here's the flip side to all this amazingness, and it's really, it's honestly, this is the [[19:26](http://www.youtube.com/watch?v=7zC8-06198g&t=1166)] key thing that I want to have an honest conversation with you because it's such an important issue. [[19:32](http://www.youtube.com/watch?v=7zC8-06198g&t=1172)] This question of human addiction. You know, we are animals with a prefrontal cortex, that's how I think of us. [[19:43](http://www.youtube.com/watch?v=7zC8-06198g&t=1183)] We have these addictive instincts that go back millions of years, and we often are in the [[19:50](http://www.youtube.com/watch?v=7zC8-06198g&t=1190)] mode of trying to modulate our own behavior. It turns out that the internet is incredibly good at [[19:59](http://www.youtube.com/watch?v=7zC8-06198g&t=1199)] activating our animal selves and getting them so damn excited. And your company, the company you've built, is better [[20:07](http://www.youtube.com/watch?v=7zC8-06198g&t=1207)] at it than any other company on the planet, I think. So, what are the risks of this? I mean, [[20:16](http://www.youtube.com/watch?v=7zC8-06198g&t=1216)] how, from a company point of view, for example, it's in your interest to have people on there as [[20:23](http://www.youtube.com/watch?v=7zC8-06198g&t=1223)] long as possible. So, some would say, is the first pass you want people to be addicted as long as [[20:28](http://www.youtube.com/watch?v=7zC8-06198g&t=1228)] possible. That's how advertising money will flow and so forth, and that's how your creators will be delighted. What is [[20:37](http://www.youtube.com/watch?v=7zC8-06198g&t=1237)] too much?
----------------------------------------------------------------------------------------------------


[CHUNK #152]
Chunk ID: data007_conv_29
Meeting ID: data007
Level: conversation
Text Length: 1107 characters

Text Content:
----------------------------------------------------------------------------------------------------
37](http://www.youtube.com/watch?v=7zC8-06198g&t=1237)] **Shou Chew**: I don't actually agree with that. As a company, our goal is not to optimize [[20:43](http://www.youtube.com/watch?v=7zC8-06198g&t=1243)] and maximize time spent, it is not. In fact, in order to address people spending too much time on our [[20:50](http://www.youtube.com/watch?v=7zC8-06198g&t=1250)] platform, we have done a number of things. I was just speaking with some of your colleagues backstage. One [[20:55](http://www.youtube.com/watch?v=7zC8-06198g&t=1255)] of them, Tony, you know, she has encountered this as well. If you spend too much time on our platform, [[21:00](http://www.youtube.com/watch?v=7zC8-06198g&t=1260)] we will proactively send you videos to tell you to get off the platform. We will, and depending [[21:07](http://www.youtube.com/watch?v=7zC8-06198g&t=1267)] on the time of the day, if it's late at night, it will come sooner. We have also built in tools [[21:11](http://www.youtube.com/watch?v=7zC8-06198g&t=1271)] to limit. If you're below 18 years old, by default, we set a 60 minute default time limit.
----------------------------------------------------------------------------------------------------


[CHUNK #153]
Chunk ID: data007_conv_30
Meeting ID: data007
Level: conversation
Text Length: 97 characters

Text Content:
----------------------------------------------------------------------------------------------------
18](http://www.youtube.com/watch?v=7zC8-06198g&t=1278)] **Chris Anderson**: How many? 60 minutes?
----------------------------------------------------------------------------------------------------


[CHUNK #154]
Chunk ID: data007_conv_31
Meeting ID: data007
Level: conversation
Text Length: 1013 characters

Text Content:
----------------------------------------------------------------------------------------------------
18](http://www.youtube.com/watch?v=7zC8-06198g&t=1278)] **Shou Chew**: 60 minutes. And we've given parents tools and yourself tools. If you go to settings, you can set [[21:23](http://www.youtube.com/watch?v=7zC8-06198g&t=1283)] your own time limit. We've given parents tools so that you can pair—for the parents who don't know [[21:28](http://www.youtube.com/watch?v=7zC8-06198g&t=1288)] this, go to settings, "Family Pairing"—you can pair your phone with your teenager's phone and set the time limit. [[21:34](http://www.youtube.com/watch?v=7zC8-06198g&t=1294)] And we really encourage parents to have these conversations with their teenagers on what is the right amount of screen [[21:39](http://www.youtube.com/watch?v=7zC8-06198g&t=1299)] time. I think there's a healthy relationship that you should have with your screen, and as a business, [[21:44](http://www.youtube.com/watch?v=7zC8-06198g&t=1304)] we believe that that balance needs to be met. So, it's not true that we just want to maximize time spent.
----------------------------------------------------------------------------------------------------


[CHUNK #155]
Chunk ID: data007_conv_32
Meeting ID: data007
Level: conversation
Text Length: 271 characters

Text Content:
----------------------------------------------------------------------------------------------------
49](http://www.youtube.com/watch?v=7zC8-06198g&t=1309)] **Chris Anderson**: If you were advising parents here what time they should actually recommend to their teenagers, what [[21:56](http://www.youtube.com/watch?v=7zC8-06198g&t=1316)] do you think is the right setting?
----------------------------------------------------------------------------------------------------


[CHUNK #156]
Chunk ID: data007_conv_33
Meeting ID: data007
Level: conversation
Text Length: 1279 characters

Text Content:
----------------------------------------------------------------------------------------------------
57](http://www.youtube.com/watch?v=7zC8-06198g&t=1317)] **Shou Chew**: Well, 60 minutes, we did not come up with it ourselves. So, I [[22:01](http://www.youtube.com/watch?v=7zC8-06198g&t=1321)] went to the Digital Wellness Lab at the Boston Children's Hospital, and we had this conversation with them, [[22:05](http://www.youtube.com/watch?v=7zC8-06198g&t=1325)] and 60 minutes was the recommendation that they gave to us, which is why we built this into the app. [[22:10](http://www.youtube.com/watch?v=7zC8-06198g&t=1330)] Now, so 60 minutes, take it for what it is. It's something that we've had some discussions [[22:15](http://www.youtube.com/watch?v=7zC8-06198g&t=1335)] with experts, but I think for all parents here, it is very important to have these conversations with your teenage [[22:21](http://www.youtube.com/watch?v=7zC8-06198g&t=1341)] children, and help them, help them develop a healthy relationship with screens. I think we live in an [[22:27](http://www.youtube.com/watch?v=7zC8-06198g&t=1347)] age where it's completely inevitable that we're going to interact with screens and digital content, but I [[22:34](http://www.youtube.com/watch?v=7zC8-06198g&t=1354)] think we should develop healthy habits early on in life, and that's something I would encourage.
----------------------------------------------------------------------------------------------------


[CHUNK #157]
Chunk ID: data007_conv_34
Meeting ID: data007
Level: conversation
Text Length: 1028 characters

Text Content:
----------------------------------------------------------------------------------------------------
38](http://www.youtube.com/watch?v=7zC8-06198g&t=1358)] **Chris Anderson**: I'm curious to ask [[22:40](http://www.youtube.com/watch?v=7zC8-06198g&t=1360)] the audience, which of you have ever had that video on TikTok appear saying, "Come on, [[22:48](http://www.youtube.com/watch?v=7zC8-06198g&t=1368)] I mean..." Okay, so maybe a third of the audience seem to be active TikTok users, and about 20 people [[22:56](http://www.youtube.com/watch?v=7zC8-06198g&t=1376)] maybe put their hands up there. So, are you sure that, like, it feels to me like this [[23:01](http://www.youtube.com/watch?v=7zC8-06198g&t=1381)] is a great, this is a great thing to have, and but isn't there always going [[23:08](http://www.youtube.com/watch?v=7zC8-06198g&t=1388)] to be a temptation in any given quarter or whatever to just push it a bit at the boundary and [[23:14](http://www.youtube.com/watch?v=7zC8-06198g&t=1394)] just dial back a bit on that so that you can hit revenue goals, etc., etc.? Are you saying that this is used scrupulously?
----------------------------------------------------------------------------------------------------


[CHUNK #158]
Chunk ID: data007_conv_35
Meeting ID: data007
Level: conversation
Text Length: 1033 characters

Text Content:
----------------------------------------------------------------------------------------------------
23](http://www.youtube.com/watch?v=7zC8-06198g&t=1403)] **Shou Chew**: I think, you know, in terms, even if you think [[23:26](http://www.youtube.com/watch?v=7zC8-06198g&t=1406)] about it from a commercial point of view, it is always best when your customers have a very healthy relationship [[23:31](http://www.youtube.com/watch?v=7zC8-06198g&t=1411)] with your product. It's always best when it's healthy. So, if you think about very short-term retention, maybe, but I [[23:38](http://www.youtube.com/watch?v=7zC8-06198g&t=1418)] don't think that's not the way we think about it. If you think about it from a longer term perspective, [[23:42](http://www.youtube.com/watch?v=7zC8-06198g&t=1422)] what you really want to have is a healthy relationship. You don't want people to be [[23:47](http://www.youtube.com/watch?v=7zC8-06198g&t=1427)] to develop very unhealthy habits, and then at some point they're going to drop it, right? No, so I [[23:51](http://www.youtube.com/watch?v=7zC8-06198g&t=1431)] think everything in moderation.
----------------------------------------------------------------------------------------------------


[CHUNK #159]
Chunk ID: data007_conv_36
Meeting ID: data007
Level: conversation
Text Length: 292 characters

Text Content:
----------------------------------------------------------------------------------------------------
53](http://www.youtube.com/watch?v=7zC8-06198g&t=1433)] **Chris Anderson**: There's a claim out there that in China there's a much more rigorous [[23:58](http://www.youtube.com/watch?v=7zC8-06198g&t=1438)] standards imposed on the amount of time that children, especially, can spend on the...
----------------------------------------------------------------------------------------------------


[CHUNK #160]
Chunk ID: data007_conv_37
Meeting ID: data007
Level: conversation
Text Length: 1310 characters

Text Content:
----------------------------------------------------------------------------------------------------
07](http://www.youtube.com/watch?v=7zC8-06198g&t=1447)] **Shou Chew**: That is, unfortunately, a very, it's a misconception. So, that experience that is being mentioned for Douyin, which is a [[24:14](http://www.youtube.com/watch?v=7zC8-06198g&t=1454)] different app, is for an under 14 year old experience. Now, if you compare that in the United States, we [[24:21](http://www.youtube.com/watch?v=7zC8-06198g&t=1461)] have under 13 experience in the U.S. It's only available in the U.S. It's not available here in Canada. In [[24:26](http://www.youtube.com/watch?v=7zC8-06198g&t=1466)] Canada, we just don't allow it. If you look at the under 13 experience in the U.S., it's much more [[24:31](http://www.youtube.com/watch?v=7zC8-06198g&t=1471)] restricted than the under 14 experience in China. It's so restrictive that every single piece of content is vetted by [[24:39](http://www.youtube.com/watch?v=7zC8-06198g&t=1479)] our third-party child safety expert, and we don't allow any under 13s in the U.S. to publish. We don't [[24:48](http://www.youtube.com/watch?v=7zC8-06198g&t=1488)] allow them to post, and we don't allow them to use a lot of features. So, I think that, that [[24:52](http://www.youtube.com/watch?v=7zC8-06198g&t=1492)] report—I've seen that report too—it's not doing a fair comparison.
----------------------------------------------------------------------------------------------------


[CHUNK #161]
Chunk ID: data007_conv_38
Meeting ID: data007
Level: conversation
Text Length: 764 characters

Text Content:
----------------------------------------------------------------------------------------------------
56](http://www.youtube.com/watch?v=7zC8-06198g&t=1496)] **Chris Anderson**: What do you make of this issue, [[24:58](http://www.youtube.com/watch?v=7zC8-06198g&t=1498)] you know, in a lot of your... you've got these millions of content creators, and all of them, in a sense, [[25:02](http://www.youtube.com/watch?v=7zC8-06198g&t=1502)] are in a race for attention. And that race can pull them in certain directions. So, for example, teenage [[25:11](http://www.youtube.com/watch?v=7zC8-06198g&t=1511)] girls on TikTok. Sometimes people worry that to win attention, they've discovered that by being more sexual that [[25:18](http://www.youtube.com/watch?v=7zC8-06198g&t=1518)] they can gain extra viewers. Is this a concern? Is there anything you can do about this?
----------------------------------------------------------------------------------------------------


[CHUNK #162]
Chunk ID: data007_conv_39
Meeting ID: data007
Level: conversation
Text Length: 1500 characters

Text Content:
----------------------------------------------------------------------------------------------------
22](http://www.youtube.com/watch?v=7zC8-06198g&t=1522)] **Shou Chew**: We address [[25:24](http://www.youtube.com/watch?v=7zC8-06198g&t=1524)] this in our Community Guidelines as well. You know, if you look at the sexualized content on [[25:31](http://www.youtube.com/watch?v=7zC8-06198g&t=1531)] our guidelines, if you're below a certain age, for certain themes that are mature, we actually remove [[25:37](http://www.youtube.com/watch?v=7zC8-06198g&t=1537)] that from your experience. Again, I come back to this. We want to have a safe platform. In [[25:43](http://www.youtube.com/watch?v=7zC8-06198g&t=1543)] fact, at my congressional hearing, I made four commitments to our users and to the politicians in the U.S. And [[25:49](http://www.youtube.com/watch?v=7zC8-06198g&t=1549)] one of the first one is that we take safety, especially for teenagers, extremely seriously, and we will continue to [[25:55](http://www.youtube.com/watch?v=7zC8-06198g&t=1555)] prioritize that. You know, I believe that we need to give our teenage users and our users in general a [[26:02](http://www.youtube.com/watch?v=7zC8-06198g&t=1562)] very safe experience because if we don't do that, then we cannot... the mission is to inspire creativity and to [[26:07](http://www.youtube.com/watch?v=7zC8-06198g&t=1567)] bring joy, right? If they don't feel safe, I cannot fulfill my mission. So, it's all very organic to [[26:13](http://www.youtube.com/watch?v=7zC8-06198g&t=1573)] me as a business to make sure I do that.
----------------------------------------------------------------------------------------------------


[CHUNK #163]
Chunk ID: data007_conv_40
Meeting ID: data007
Level: conversation
Text Length: 583 characters

Text Content:
----------------------------------------------------------------------------------------------------
14](http://www.youtube.com/watch?v=7zC8-06198g&t=1574)] **Chris Anderson**: But in the strange interacting world of human psychology, and [[26:19](http://www.youtube.com/watch?v=7zC8-06198g&t=1579)] so forth, weird memes can take off. I mean, you had this outbreak a couple years back of these "devious [[26:24](http://www.youtube.com/watch?v=7zC8-06198g&t=1584)] licks" where kids were competing with each other to do vandalism in schools and get lots of followers [[26:30](http://www.youtube.com/watch?v=7zC8-06198g&t=1590)] from it. How on Earth do you battle something like that?
----------------------------------------------------------------------------------------------------


[CHUNK #164]
Chunk ID: data007_conv_41
Meeting ID: data007
Level: conversation
Text Length: 1094 characters

Text Content:
----------------------------------------------------------------------------------------------------
34](http://www.youtube.com/watch?v=7zC8-06198g&t=1594)] **Shou Chew**: Dangerous challenges are not allowed on our [[26:36](http://www.youtube.com/watch?v=7zC8-06198g&t=1596)] platform. It's, if you look at our guidelines, it's violative. We proactively invest resources to identify them and [[26:43](http://www.youtube.com/watch?v=7zC8-06198g&t=1603)] remove them from our platform. In fact, if you search for dangerous challenges on our platform today, we will redirect [[26:49](http://www.youtube.com/watch?v=7zC8-06198g&t=1609)] you to a safety resource page. And we actually worked with some creators as well to come up with campaigns, [[26:54](http://www.youtube.com/watch?v=7zC8-06198g&t=1614)] and this is another campaign, it's the "Stop, Think, Decide Before You Act" campaign, where we work with the creators [[27:00](http://www.youtube.com/watch?v=7zC8-06198g&t=1620)] to produce videos to explain to people that some of things are dangerous, please don't do it. And we post [[27:06](http://www.youtube.com/watch?v=7zC8-06198g&t=1626)] those videos actively on our platform as well.
----------------------------------------------------------------------------------------------------


[CHUNK #165]
Chunk ID: data007_conv_42
Meeting ID: data007
Level: conversation
Text Length: 572 characters

Text Content:
----------------------------------------------------------------------------------------------------
08](http://www.youtube.com/watch?v=7zC8-06198g&t=1628)] **Chris Anderson**: That's cool. And you've got, you've got lots of employees. [[27:12](http://www.youtube.com/watch?v=7zC8-06198g&t=1632)] I mean, how many employees do you have who are specifically looking at these content moderation things? Or is that [[27:19](http://www.youtube.com/watch?v=7zC8-06198g&t=1639)] the wrong question? Are they mostly identified by AI initially, and then you have a group [[27:24](http://www.youtube.com/watch?v=7zC8-06198g&t=1644)] who are overseeing and making the final decision?
----------------------------------------------------------------------------------------------------


[CHUNK #166]
Chunk ID: data007_conv_43
Meeting ID: data007
Level: conversation
Text Length: 1334 characters

Text Content:
----------------------------------------------------------------------------------------------------
26](http://www.youtube.com/watch?v=7zC8-06198g&t=1646)] **Shou Chew**: The group is based in Ireland, and it's a [[27:30](http://www.youtube.com/watch?v=7zC8-06198g&t=1650)] lot of people. It's tens of thousands of people. Tens of, tens of thousands. It's a huge, it's one of [[27:35](http://www.youtube.com/watch?v=7zC8-06198g&t=1655)] the most important cost items of my P&L, and I think it's completely worth it. Now, most of the [[27:40](http://www.youtube.com/watch?v=7zC8-06198g&t=1660)] moderation has to be done by machines. The machines are good, they're quite good, but they're not as good as, [[27:46](http://www.youtube.com/watch?v=7zC8-06198g&t=1666)] you know, they're not perfect at this point. So, you have to complement them with a lot of human beings [[27:51](http://www.youtube.com/watch?v=7zC8-06198g&t=1671)] today. And I think, by the way, a lot of the progress in AI in general is making that kind [[27:57](http://www.youtube.com/watch?v=7zC8-06198g&t=1677)] of content moderation capabilities a lot better. So, we're going to get more precise, we're going to get more [[28:03](http://www.youtube.com/watch?v=7zC8-06198g&t=1683)] specific, and it's going to be able to handle larger scale, and that's something [[28:09](http://www.youtube.com/watch?v=7zC8-06198g&t=1689)] that I'm personally looking forward to.
----------------------------------------------------------------------------------------------------


[CHUNK #167]
Chunk ID: data007_conv_44
Meeting ID: data007
Level: conversation
Text Length: 653 characters

Text Content:
----------------------------------------------------------------------------------------------------
10](http://www.youtube.com/watch?v=7zC8-06198g&t=1690)] **Chris Anderson**: What about this perceived huge downside of use of certainly [[28:20](http://www.youtube.com/watch?v=7zC8-06198g&t=1700)] Instagram, I think TikTok as well, where people worry that you are amplifying insecurities, especially of teenagers, and [[28:27](http://www.youtube.com/watch?v=7zC8-06198g&t=1707)] perhaps especially teenage girls. That you see, they see these amazing people on there doing amazing things, they feel inadequate. [[28:34](http://www.youtube.com/watch?v=7zC8-06198g&t=1714)] There's all these reported cases of depression, insecurity, suicide, and so forth.
----------------------------------------------------------------------------------------------------


[CHUNK #168]
Chunk ID: data007_conv_45
Meeting ID: data007
Level: conversation
Text Length: 1256 characters

Text Content:
----------------------------------------------------------------------------------------------------
38](http://www.youtube.com/watch?v=7zC8-06198g&t=1718)] **Shou Chew**: I take this extremely seriously. [[28:42](http://www.youtube.com/watch?v=7zC8-06198g&t=1722)] So, again, in our guidelines, for certain themes that we think are mature [[28:50](http://www.youtube.com/watch?v=7zC8-06198g&t=1730)] and not suitable for teenagers, we actually proactively remove it from their experience. At the same time, if you search certain terms, we will make [[28:57](http://www.youtube.com/watch?v=7zC8-06198g&t=1737)] sure that you get redirected to a resource safety page. Now, we're always working with experts to understand some of [[29:04](http://www.youtube.com/watch?v=7zC8-06198g&t=1744)] these new trends that could emerge and proactively try to manage and try to manage them, if that makes sense. [[29:10](http://www.youtube.com/watch?v=7zC8-06198g&t=1750)] Now, this is a problem that predates us. It predates TikTok. It actually predates the internet. [[29:16](http://www.youtube.com/watch?v=7zC8-06198g&t=1756)] But it's our responsibility to make sure that we invest enough to understand and to address the concerns to [[29:22](http://www.youtube.com/watch?v=7zC8-06198g&t=1762)] keep the experience as safe as possible for as many people as possible.
----------------------------------------------------------------------------------------------------


[CHUNK #169]
Chunk ID: data007_conv_46
Meeting ID: data007
Level: conversation
Text Length: 1190 characters

Text Content:
----------------------------------------------------------------------------------------------------
25](http://www.youtube.com/watch?v=7zC8-06198g&t=1765)] **Chris Anderson**: Now, in Congress, the main concern [[29:28](http://www.youtube.com/watch?v=7zC8-06198g&t=1768)] seemed to be not so much what we've talked about, but data—the data of users, the fact that [[29:34](http://www.youtube.com/watch?v=7zC8-06198g&t=1774)] you're owned by ByteDance, Chinese company, and the concern that at any moment [[29:42](http://www.youtube.com/watch?v=7zC8-06198g&t=1782)] Chinese government might require or ask for data. And in fact, there have been instances where I think you've confirmed that some data [[29:48](http://www.youtube.com/watch?v=7zC8-06198g&t=1788)] of journalists on the platform was made available to ByteDance's engineers, and from there, who knows what? [[29:55](http://www.youtube.com/watch?v=7zC8-06198g&t=1795)] Now, your response to this was to have this Project Texas, where you're moving data to be [[30:03](http://www.youtube.com/watch?v=7zC8-06198g&t=1803)] controlled by Oracle here in the U.S. Can you talk about that project, and why, [[30:09](http://www.youtube.com/watch?v=7zC8-06198g&t=1809)] if you believe it, why we should not worry so much about this issue?
----------------------------------------------------------------------------------------------------


[CHUNK #170]
Chunk ID: data007_conv_47
Meeting ID: data007
Level: conversation
Text Length: 3008 characters

Text Content:
----------------------------------------------------------------------------------------------------
12](http://www.youtube.com/watch?v=7zC8-06198g&t=1812)] **Shou Chew**: I will say a couple [[30:14](http://www.youtube.com/watch?v=7zC8-06198g&t=1814)] of things about this, if you don't mind. The first thing I would say is that the internet is built [[30:19](http://www.youtube.com/watch?v=7zC8-06198g&t=1819)] on global interoperability, and we are not the only company that relies on a global talent pool to make our [[30:25](http://www.youtube.com/watch?v=7zC8-06198g&t=1825)] products as good as technology is a very collaborative effort. I think many people here would say the [[30:31](http://www.youtube.com/watch?v=7zC8-06198g&t=1831)] same thing. So, we are not the first company to have engineers in all countries, including in China. We're not [[30:36](http://www.youtube.com/watch?v=7zC8-06198g&t=1836)] the first one. Now, I understand some of these concerns. So, the data access by employees is not [[30:44](http://www.youtube.com/watch?v=7zC8-06198g&t=1844)] data accessed by government. This is very different, and there's a clear difference in this. But we hear the concerns [[30:49](http://www.youtube.com/watch?v=7zC8-06198g&t=1849)] that are raised in the United States. We did not try to avoid discussing, or we did not [[30:55](http://www.youtube.com/watch?v=7zC8-06198g&t=1855)] try to argue our way out of it. What we did was, we built an unprecedented project where we localized [[31:01](http://www.youtube.com/watch?v=7zC8-06198g&t=1861)] American data to be stored on American soil by an American company, overseen by American personnel. So, this [[31:09](http://www.youtube.com/watch?v=7zC8-06198g&t=1869)] kind of protection for American data is beyond what any other company in our industry has ever done. It's [[31:17](http://www.youtube.com/watch?v=7zC8-06198g&t=1877)] well, money is not the only issue here, but it's very expensive to build something like that. And more importantly, [[31:23](http://www.youtube.com/watch?v=7zC8-06198g&t=1883)] we are basically localizing data in a way that no other company has done. So, we need to be [[31:29](http://www.youtube.com/watch?v=7zC8-06198g&t=1889)] very careful that whilst we are pursuing data, what we call digital sovereignty in the U.S., and we're also doing [[31:36](http://www.youtube.com/watch?v=7zC8-06198g&t=1896)] a version of this in Europe, that we don't balkanize the internet. Now, we are the first to do it, [[31:41](http://www.youtube.com/watch?v=7zC8-06198g&t=1901)] and I expect that other companies are probably looking at this and trying to figure out how you [[31:46](http://www.youtube.com/watch?v=7zC8-06198g&t=1906)] balance between protecting protected data, to make sure that everybody feels secure about it, while at the same [[31:53](http://www.youtube.com/watch?v=7zC8-06198g&t=1913)] time allowing for interoperability to continue to happen because that's what makes technology and the internet so great. That's something [[32:00](http://www.youtube.com/watch?v=7zC8-06198g&t=1920)] that we are.
----------------------------------------------------------------------------------------------------


[CHUNK #171]
Chunk ID: data007_conv_48
Meeting ID: data007
Level: conversation
Text Length: 130 characters

Text Content:
----------------------------------------------------------------------------------------------------
00](http://www.youtube.com/watch?v=7zC8-06198g&t=1920)] **Chris Anderson**: How far are you along that journey with Project Texas?
----------------------------------------------------------------------------------------------------


[CHUNK #172]
Chunk ID: data007_conv_49
Meeting ID: data007
Level: conversation
Text Length: 1071 characters

Text Content:
----------------------------------------------------------------------------------------------------
04](http://www.youtube.com/watch?v=7zC8-06198g&t=1924)] **Shou Chew**: We are very, very far along today. [[32:05](http://www.youtube.com/watch?v=7zC8-06198g&t=1925)] When, when, when will there be a clear, you know, "Here it is, it's done." [[32:11](http://www.youtube.com/watch?v=7zC8-06198g&t=1931)] All new U.S. data is already stored in the Oracle Cloud Infrastructure. So, it's in [[32:19](http://www.youtube.com/watch?v=7zC8-06198g&t=1939)] this protected U.S. environment that we talked about. In the United States, we still have some legacy data to delete [[32:25](http://www.youtube.com/watch?v=7zC8-06198g&t=1945)] in our own servers in Virginia and in Singapore. Our data has never been stored in China, by the [[32:30](http://www.youtube.com/watch?v=7zC8-06198g&t=1950)] way. That deletion is a very big engineering effort, so as I said at the hearing, it's [[32:36](http://www.youtube.com/watch?v=7zC8-06198g&t=1956)] going to take us a while to delete them, but I expect it to be [[32:39](http://www.youtube.com/watch?v=7zC8-06198g&t=1959)] done this year.
----------------------------------------------------------------------------------------------------


[CHUNK #173]
Chunk ID: data007_conv_50
Meeting ID: data007
Level: conversation
Text Length: 1052 characters

Text Content:
----------------------------------------------------------------------------------------------------
47](http://www.youtube.com/watch?v=7zC8-06198g&t=1967)] **Chris Anderson**: How much power do you have over your own ability to control certain things? So, for [[32:50](http://www.youtube.com/watch?v=7zC8-06198g&t=1970)] for example, suppose that for whatever reason the Chinese government was to look at an upcoming U.S. election and say, [[32:57](http://www.youtube.com/watch?v=7zC8-06198g&t=1977)] "you know what, we would like this party to win," let's say, or "we would like civil war to break [[33:03](http://www.youtube.com/watch?v=7zC8-06198g&t=1983)] out," or whatever. And we could do this by amplifying the content of certain troublemaking, disturbing people, causing uncertainty, [[33:13](http://www.youtube.com/watch?v=7zC8-06198g&t=1993)] spreading misinformation, etc. Were you required via ByteDance to do this? Is there [[33:22](http://www.youtube.com/watch?v=7zC8-06198g&t=2002)] a pathway where theoretically that's possible? What's your personal line in the sand [[33:29](http://www.youtube.com/watch?v=7zC8-06198g&t=2009)] on this?
----------------------------------------------------------------------------------------------------


[CHUNK #174]
Chunk ID: data007_conv_51
Meeting ID: data007
Level: conversation
Text Length: 2202 characters

Text Content:
----------------------------------------------------------------------------------------------------
30](http://www.youtube.com/watch?v=7zC8-06198g&t=2010)] **Shou Chew**: So, during the congressional hearing I made four commitments. We talked about the first one, [[33:35](http://www.youtube.com/watch?v=7zC8-06198g&t=2015)] which is safety. The third one is to keep TikTok a place of freedom of expression. By the way, [[33:40](http://www.youtube.com/watch?v=7zC8-06198g&t=2020)] if you go on TikTok today, you can search for anything you want as long as it doesn't violate [[33:44](http://www.youtube.com/watch?v=7zC8-06198g&t=2024)] our Community Guidelines, and to keep it free from any government manipulation. And the fourth one is transparency and third-party [[33:52](http://www.youtube.com/watch?v=7zC8-06198g&t=2032)] monitoring. So, the way we are trying to address this concern is an unprecedented amount of transparency. What do I [[33:58](http://www.youtube.com/watch?v=7zC8-06198g&t=2038)] mean by this? We're actually allowing third-party reviewers to come in and review our source code. I don't know any [[34:05](http://www.youtube.com/watch?v=7zC8-06198g&t=2045)] other company that does this, by the way, just so because everything, as you know, is driven by code. [[34:10](http://www.youtube.com/watch?v=7zC8-06198g&t=2050)] So, to allow someone else to review the source code is to give this a significant amount of transparency to [[34:17](http://www.youtube.com/watch?v=7zC8-06198g&t=2057)] ensure that the design areas that you described, this highly hypothetical, cannot happen on our platform. Now, at the same [[34:23](http://www.youtube.com/watch?v=7zC8-06198g&t=2063)] time, we are releasing more research tools for researchers so that they can study the output. So, you know, the [[34:30](http://www.youtube.com/watch?v=7zC8-06198g&t=2070)] source code is the input. We are also allowing researchers to study the output, which is the content on our [[34:35](http://www.youtube.com/watch?v=7zC8-06198g&t=2075)] platform. I think the easiest way to sort of defend this is transparency. We give people access [[34:42](http://www.youtube.com/watch?v=7zC8-06198g&t=2082)] to to monitor us, and we can just make it very, very transparent, and that's our approach to the problem.
----------------------------------------------------------------------------------------------------


[CHUNK #175]
Chunk ID: data007_conv_52
Meeting ID: data007
Level: conversation
Text Length: 315 characters

Text Content:
----------------------------------------------------------------------------------------------------
45](http://www.youtube.com/watch?v=7zC8-06198g&t=2085)] **Chris Anderson**: So, you will say directly to this group that the scenario I talked about of theoretical Chinese government [[34:54](http://www.youtube.com/watch?v=7zC8-06198g&t=2094)] interference in an American election, you can say that will not happen.
----------------------------------------------------------------------------------------------------


[CHUNK #176]
Chunk ID: data007_conv_53
Meeting ID: data007
Level: conversation
Text Length: 509 characters

Text Content:
----------------------------------------------------------------------------------------------------
57](http://www.youtube.com/watch?v=7zC8-06198g&t=2097)] **Shou Chew**: I can say that we are building all [[35:01](http://www.youtube.com/watch?v=7zC8-06198g&t=2101)] the tools to prevent any of these actions from happening. And I'm very confident that with an unprecedented [[35:08](http://www.youtube.com/watch?v=7zC8-06198g&t=2108)] amount of transparency that we're giving on the platform, we can reduce this risk to as low [[35:15](http://www.youtube.com/watch?v=7zC8-06198g&t=2115)] as zero as possible.
----------------------------------------------------------------------------------------------------


[CHUNK #177]
Chunk ID: data007_conv_54
Meeting ID: data007
Level: conversation
Text Length: 106 characters

Text Content:
----------------------------------------------------------------------------------------------------
18](http://www.youtube.com/watch?v=7zC8-06198g&t=2118)] **Chris Anderson**: To as low as zero as possible.
----------------------------------------------------------------------------------------------------


[CHUNK #178]
Chunk ID: data007_conv_55
Meeting ID: data007
Level: conversation
Text Length: 103 characters

Text Content:
----------------------------------------------------------------------------------------------------
21](http://www.youtube.com/watch?v=7zC8-06198g&t=2121)] **Shou Chew**: To as close to zero as possible.
----------------------------------------------------------------------------------------------------


[CHUNK #179]
Chunk ID: data007_conv_56
Meeting ID: data007
Level: conversation
Text Length: 643 characters

Text Content:
----------------------------------------------------------------------------------------------------
23](http://www.youtube.com/watch?v=7zC8-06198g&t=2123)] **Chris Anderson**: As close [[35:23](http://www.youtube.com/watch?v=7zC8-06198g&t=2123)] to zero as possible. That's fairly reassuring. Fairly. [[35:32](http://www.youtube.com/watch?v=7zC8-06198g&t=2132)] I mean, how would the world know? And what would, like, if you discovered this or you thought you had [[35:36](http://www.youtube.com/watch?v=7zC8-06198g&t=2136)] to do it, is this a line in the sand for you? Like, are you at a situation, [[35:42](http://www.youtube.com/watch?v=7zC8-06198g&t=2142)] you would not let the company that you know now and that you are running do this?
----------------------------------------------------------------------------------------------------


[CHUNK #180]
Chunk ID: data007_conv_57
Meeting ID: data007
Level: conversation
Text Length: 676 characters

Text Content:
----------------------------------------------------------------------------------------------------
45](http://www.youtube.com/watch?v=7zC8-06198g&t=2145)] **Shou Chew**: Absolutely. That's the [[35:47](http://www.youtube.com/watch?v=7zC8-06198g&t=2147)] reason why we're letting third parties monitor them, because if they find out, they will disclose this. [[35:52](http://www.youtube.com/watch?v=7zC8-06198g&t=2152)] We also have transparency reports, by the way, where we talk about a whole bunch of things, the [[35:57](http://www.youtube.com/watch?v=7zC8-06198g&t=2157)] content that we remove, that violates our guidelines, government requests. It's all published online. All you [[36:03](http://www.youtube.com/watch?v=7zC8-06198g&t=2163)] have to do is search for it.
----------------------------------------------------------------------------------------------------


[CHUNK #181]
Chunk ID: data007_conv_58
Meeting ID: data007
Level: conversation
Text Length: 599 characters

Text Content:
----------------------------------------------------------------------------------------------------
05](http://www.youtube.com/watch?v=7zC8-06198g&t=2165)] **Chris Anderson**: So, you're super compelling and likable as a CEO, I have to say. [[36:08](http://www.youtube.com/watch?v=7zC8-06198g&t=2168)] And I would like to, as we wrap this up, I'd like to give you a chance just to [[36:12](http://www.youtube.com/watch?v=7zC8-06198g&t=2172)] paint, like, what's the vision? As you look at what TikTok could be, let's move the clock [[36:19](http://www.youtube.com/watch?v=7zC8-06198g&t=2179)] out, say, five, five years from now. How should we think about your contribution to our collective future?
----------------------------------------------------------------------------------------------------


[CHUNK #182]
Chunk ID: data007_conv_59
Meeting ID: data007
Level: conversation
Text Length: 3157 characters

Text Content:
----------------------------------------------------------------------------------------------------
25](http://www.youtube.com/watch?v=7zC8-06198g&t=2185)] **Shou Chew**: I think it's still down to the vision that we have. So, in terms of the window of discovery, I think [[36:32](http://www.youtube.com/watch?v=7zC8-06198g&t=2192)] there's a huge benefit to the world when people can discover new things. You know, people think that TikTok [[36:38](http://www.youtube.com/watch?v=7zC8-06198g&t=2198)] is all about dancing and singing, and there's nothing wrong with that because it's super fun. There's still a lot [[36:43](http://www.youtube.com/watch?v=7zC8-06198g&t=2203)] of that, but we're seeing science content, STEM content. Have you heard about "BookTok"? It's a [[36:49](http://www.youtube.com/watch?v=7zC8-06198g&t=2209)] viral trend that talks about books and encourages people to read. That "BookTok" has 120 billion views globally. 120 [[36:58](http://www.youtube.com/watch?v=7zC8-06198g&t=2218)] billion, billion with a B. People are learning how to cook. People are learning about science. People [[37:03](http://www.youtube.com/watch?v=7zC8-06198g&t=2223)] are learning how to golf. Well, people are watching videos on golfing, I guess. I haven't gotten better. [[37:13](http://www.youtube.com/watch?v=7zC8-06198g&t=2233)] And I think there's a huge opportunity here on discovery and giving the everyday person a voice. If you talk to our [[37:19](http://www.youtube.com/watch?v=7zC8-06198g&t=2239)] creators, a lot of people will tell you this again and again, that before TikTok, they [[37:24](http://www.youtube.com/watch?v=7zC8-06198g&t=2244)] would never have been discovered, and we have given them the platform to do that. It's important to maintain that. [[37:29](http://www.youtube.com/watch?v=7zC8-06198g&t=2249)] We talk about creation. There's all these new technology coming in with AI generative content that [[37:36](http://www.youtube.com/watch?v=7zC8-06198g&t=2256)] will help people create even more creative content. I think there's going to be a collaboration between—and I [[37:42](http://www.youtube.com/watch?v=7zC8-06198g&t=2262)] think there's a speaker who's going to talk about this—people and AI, where they can unleash their creativity [[37:48](http://www.youtube.com/watch?v=7zC8-06198g&t=2268)] in a different way. Like, for example, I'm terrible at drawing personally, but if I had somebody [[37:54](http://www.youtube.com/watch?v=7zC8-06198g&t=2274)] to help me, then maybe I can express myself even better. Then we talk about bridges to connect, [[37:59](http://www.youtube.com/watch?v=7zC8-06198g&t=2279)] and connecting people in the communities together. This could be products, this could be commerce. 5 million small [[38:06](http://www.youtube.com/watch?v=7zC8-06198g&t=2286)] businesses in the U.S. benefit from TikTok today. I think we can get that number to a much [[38:11](http://www.youtube.com/watch?v=7zC8-06198g&t=2291)] higher number, and of course, if you look around the world, including in Canada, that number is going to be [[38:15](http://www.youtube.com/watch?v=7zC8-06198g&t=2295)] massive. So, I think these are the biggest opportunities that we have, and it's really very exciting.
----------------------------------------------------------------------------------------------------


[CHUNK #183]
Chunk ID: data007_conv_60
Meeting ID: data007
Level: conversation
Text Length: 415 characters

Text Content:
----------------------------------------------------------------------------------------------------
16](http://www.youtube.com/watch?v=7zC8-06198g&t=2296)] **Chris Anderson**: So, courtesy [[38:22](http://www.youtube.com/watch?v=7zC8-06198g&t=2302)] of your experience in Congress, you actually became a bit of a TikTok star yourself, I think. Some [[38:29](http://www.youtube.com/watch?v=7zC8-06198g&t=2309)] of your videos have gone viral. How about, you've got your phone with you, little TikTok video right now?
----------------------------------------------------------------------------------------------------


[CHUNK #184]
Chunk ID: data007_conv_61
Meeting ID: data007
Level: conversation
Text Length: 400 characters

Text Content:
----------------------------------------------------------------------------------------------------
35](http://www.youtube.com/watch?v=7zC8-06198g&t=2315)] **Shou Chew**: If the audience doesn't do this, if you don't mind, we're just going to do a selfie together. How's that? [[38:40](http://www.youtube.com/watch?v=7zC8-06198g&t=2320)] Okay, so why don't we just say, "Hi, hi, hello from TED!" All right, thank you. I hope it goes [[38:50](http://www.youtube.com/watch?v=7zC8-06198g&t=2330)] viral.
----------------------------------------------------------------------------------------------------


[CHUNK #185]
Chunk ID: data007_conv_62
Meeting ID: data007
Level: conversation
Text Length: 696 characters

Text Content:
----------------------------------------------------------------------------------------------------
50](http://www.youtube.com/watch?v=7zC8-06198g&t=2330)] **Chris Anderson**: If that one goes viral, I think I've given up on your algorithm, actually. I think it's going to, it's [[38:57](http://www.youtube.com/watch?v=7zC8-06198g&t=2337)] going to take better. You're one of the most influential and powerful people in the world, whether you know it [[39:05](http://www.youtube.com/watch?v=7zC8-06198g&t=2345)] or not, and I really appreciate you coming and sharing your vision. I really, really hope the upside of what [[39:10](http://www.youtube.com/watch?v=7zC8-06198g&t=2350)] you're talking about comes about. Thank you so much. Thank you, thank you, thank you, thank you, thank you, thank.
----------------------------------------------------------------------------------------------------


