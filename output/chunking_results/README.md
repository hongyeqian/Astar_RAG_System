# Hierarchical Chunking Test Results

**Generated Date**: 2025-11-06  
**Project**: DevelopmentRAG System  
**Purpose**: Demonstrate hierarchical chunking strategy for RAG system

---

## ðŸ“ File Structure

This directory contains the results of hierarchical chunking performed on 8 meeting transcripts.

### Output Files

1. **`chunking_summary_report.txt`** - Overall statistics and summary
2. **`metadata_level_chunks.txt`** - Metadata level (8 chunks)
3. **`summary_level_chunks.txt`** - Summary level (8 chunks)
4. **`meeting_level_chunks.txt`** - Meeting level (184 chunks)
5. **`conversation_level_chunks.txt`** - Conversation level (632 chunks)
6. **`chunk_level_chunks.txt`** - Fine-grained chunk level (506 chunks)

---

## ðŸŽ¯ Hierarchical Chunking Strategy

Our RAG system implements a **5-level hierarchical chunking** approach, inspired by the architecture diagram:

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Level 1: METADATA                  â”‚  â† Filter by time, entities, topics
â”‚  (8 chunks, ~946 chars avg)         â”‚     Using LLM to extract filters
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ Reduced Search Space
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Level 2: SUMMARY                   â”‚  â† Coarse semantic search
â”‚  (8 chunks, ~1078 chars avg)        â”‚     Whole meeting overview
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Level 3: MEETING                   â”‚  â† Paragraph-level search
â”‚  (184 chunks, ~177 chars avg)       â”‚     Meeting sections
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Level 4: CONVERSATION              â”‚  â† Speaker turn-level
â”‚  (632 chunks, ~451 chars avg)       â”‚     Conversation exchanges
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Level 5: CHUNK                     â”‚  â† Fine-grained retrieval
â”‚  (506 chunks, ~616 chars avg)       â”‚     Detailed content
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Š Statistics Summary

### Overall
- **Total Chunks**: 1,338 across all levels
- **Source Meetings**: 8 meeting transcripts
- **Languages**: English

### Distribution by Level
| Level        | Chunks | Percentage | Avg Length | Purpose                    |
|--------------|--------|------------|------------|----------------------------|
| Metadata     | 8      | 0.60%      | 946 chars  | Filter & metadata search   |
| Summary      | 8      | 0.60%      | 1,078 chars| High-level semantic search |
| Meeting      | 184    | 13.75%     | 177 chars  | Section-level retrieval    |
| Conversation | 632    | 47.23%     | 451 chars  | Turn-by-turn dialogue      |
| Chunk        | 506    | 37.82%     | 616 chars  | Fine-grained content       |

---

## ðŸ” How to Review the Results

### 1. Start with the Summary Report
```bash
# Open the summary report first
open chunking_summary_report.txt
```
This gives you an overview of:
- Total chunk counts per level
- Per-meeting statistics
- Text length statistics

### 2. Examine Each Level

#### **Metadata Level** (`metadata_level_chunks.txt`)
- Shows how meeting metadata is formatted for embedding
- Used for first-stage filtering based on:
  - Time ranges
  - Participant names
  - Organizations
  - Topics and keywords

**Example Use Case**: *"Find meetings with Elon Musk discussing AI safety in 2025"*

#### **Summary Level** (`summary_level_chunks.txt`)
- Contains full meeting summaries
- Provides high-level semantic understanding
- Used for initial semantic retrieval

**Example Use Case**: *"What meetings discuss AR/VR technology?"*

#### **Meeting Level** (`meeting_level_chunks.txt`)
- Paragraphs from meeting summaries
- Medium granularity for contextual retrieval
- Maintains meeting structure

**Example Use Case**: *"Find specific sections about AI scaling limits"*

#### **Conversation Level** (`conversation_level_chunks.txt`)
- Individual speaker turns
- Preserves dialogue structure
- Captures Q&A patterns

**Example Use Case**: *"What did Mark Zuckerberg say about open source AI?"*

#### **Chunk Level** (`chunk_level_chunks.txt`)
- Fine-grained text segments (~800 chars with 120 overlap)
- Dense semantic retrieval
- Most detailed level

**Example Use Case**: *"Find exact quotes about physics-based reasoning"*

---

## ðŸ“ File Format

Each chunk file follows this structure:

```
====================================================================================================
HIERARCHICAL CHUNKING RESULTS - [LEVEL] LEVEL
Generated: [Timestamp]
Total Chunks: [Count]
====================================================================================================

>>> MEETING: [meeting_id] <<<
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[CHUNK #N]
Chunk ID: [unique_id]
Meeting ID: [meeting_id]
Level: [level]
Text Length: [N] characters

Metadata:
  - key: value
  - ...

Text Content:
----------------------------------------------------------------------------------------------------
[Actual chunk text content]
----------------------------------------------------------------------------------------------------


[Next chunk...]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

>>> MEETING: [next_meeting_id] <<<
...
```

**Key Elements**:
- `â”` Double lines separate different meetings
- `â”€` Single lines separate metadata from content
- Each chunk includes full metadata for context
- Chunks are grouped by meeting for easy navigation

---

## ðŸŽ“ Verification Checklist

When reviewing the chunking results, verify:

### âœ… Metadata Level
- [ ] All 8 meetings have metadata chunks
- [ ] Metadata includes all required fields (title, datetime, participants, topics, etc.)
- [ ] Text format is suitable for embedding

### âœ… Summary Level
- [ ] Each meeting has exactly 1 summary chunk
- [ ] Summaries are comprehensive and self-contained
- [ ] Average length is reasonable (500-2000 chars)

### âœ… Meeting Level
- [ ] Chunks follow meeting structure (sections, paragraphs)
- [ ] No chunks are too small (<10 chars) or too large (>1000 chars)
- [ ] Context is preserved in each chunk

### âœ… Conversation Level
- [ ] Each chunk corresponds to a speaker turn
- [ ] Speaker names are preserved in metadata
- [ ] Dialogue flow is maintained

### âœ… Chunk Level
- [ ] Chunks are approximately 800 chars (Â±200)
- [ ] Overlap of ~120 chars maintains context
- [ ] No loss of important content at chunk boundaries

---

## ðŸš€ Next Steps

After verifying the chunking logic:

1. **Implement Embedding Module**
   ```
   src/embeddings/embedding_manager.py
   ```
   - Generate embeddings for all chunk levels
   - Use OpenAI's text-embedding-3-small or similar

2. **Implement Vector Store**
   ```
   src/indexing/vector_indexer.py
   ```
   - Index chunks into FAISS/Chroma/Pinecone
   - Maintain separate indices per level (optional)

3. **Implement Hybrid Retrieval** (Optional for production)
   ```
   src/indexing/elasticsearch_indexer.py
   src/retrieval/hybrid_retriever.py
   ```
   - Index metadata to Elasticsearch
   - Implement LLM-based filter extraction
   - Combine ES filtering with vector search

---

## ðŸ“š Technical Details

### Chunking Configuration
```python
CHUNK_SIZE = 800        # Target chunk size in characters
CHUNK_OVERLAP = 120     # Overlap between chunks
```

### Text Splitter
- **Library**: LangChain RecursiveCharacterTextSplitter
- **Separators**: `["\n\n", "\n", "ã€‚", "ï¼›", "ï¼Œ", " ", ""]`
- **Purpose**: Maintain semantic boundaries while chunking

### Metadata Preservation
Each chunk carries forward relevant metadata:
- `meeting_id`: Links chunk back to source meeting
- `title`: Meeting title for context
- `datetime`: Temporal information
- `topics`, `keywords`: Semantic tags
- `level`: Identifies chunk granularity
- Level-specific metadata (e.g., `speaker`, `paragraph_index`)

---

## ðŸ“– References

- **Project Architecture**: See main project diagram for RAG flow
- **LangChain Documentation**: https://python.langchain.com/docs/modules/data_connection/document_transformers/
- **RAG Best Practices**: Hierarchical retrieval improves precision and recall

---

**For questions or issues, please contact the development team.**
